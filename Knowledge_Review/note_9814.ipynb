{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c95b42",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf854ab0",
   "metadata": {},
   "source": [
    "1.1.Agent\n",
    "    Reactive Agentååº”ï¼šåŸºäºå½“å‰æ„ŸçŸ¥è¡ŒåŠ¨ï¼Œè·¯å¾„å¯èƒ½æ¬¡ä¼˜. \n",
    "    Model-based AgentåŸºäºæ¨¡å‹ï¼šè·Ÿè¸ªçœ‹ä¸åˆ°äº‹ç‰©æ¥å¤„ç†éƒ¨åˆ†å¯è§‚æµ‹æ€§ï¼Œä½†ä¸èƒ½è®¡åˆ’æœªæ¥ï¼Œå®ç°ä¾‹å¦‚è‡ªåŠ¨é©¾é©¶/æ‰«åœ°æœºå™¨äºº. \n",
    "    Planning Agentè§„åˆ’ï¼šä¸æ¡ä»¶è¡ŒåŠ¨ä¸åŒï¼Œæœ‰æœªæ¥åæœè€ƒè™‘ï¼Œéœ€è¦æœç´¢ï¼Œçµæ´»æ˜“å˜ä½†ååº”æ…¢. \n",
    "        ä¾‹å¦‚ï¼šGoal-based AgentåŸºäºç›®æ ‡ï¼šåœ°å›¾æœç´¢ï¼Œè±¡æ£‹. \n",
    "    Learning Agentå­¦ä¹ ï¼šåŒ…å«performance element:è¯»sensorsæ¥è¡ŒåŠ¨/critic:ç»™åé¦ˆ/Learning element:ç”¨â‘¡ç¡®å®šä¿®æ”¹â‘ /problem generator:è®¾æ–°ä»»åŠ¡ï¼Œç»™ä¿¡æ¯ã€‚ä¼—æ¨¡å—éå­¤ç«‹. \n",
    "  \n",
    "1.2.Searchï¼šç­–ç•¥ä¸åŒåœ¨äºæ‰©å¤§è¾¹ç•Œæ–¹å¼. \n",
    "\n",
    "1.2.1.uninformedï¼š  \n",
    "    BFSå¹¿åº¦ï¼š  \n",
    "    DFSæ·±åº¦ï¼šå †æ ˆï¼ˆé™¤iddfså¤–å…¶ä»–éƒ½é˜Ÿåˆ—ï¼‰. \n",
    "    IDDFSè¿­ä»£æ·±åŒ–æ·±åº¦ï¼šä¸è¶…ç»™å®šæ·±åº¦è¿­ä»£dfs. \n",
    "    UCSç»Ÿä¸€æˆæœ¬ï¼šé€‰pathå¼§çš„å’Œæœ€å°‘ï¼Œæˆæœ¬ç›¸åŒå˜bfs. \n",
    "\n",
    "1.2.2.informedçŸ¥æƒ…æœç´¢ï¼šå¯å‘å¼ï¼Œç”¨domain knowledgeï¼Œæœæœ€ä½³çŒœæµ‹ç›®æ ‡è¡Œ. \n",
    "    GBFSè´ªå©ªï¼šé€‰æœ€ä½heuristic cost. \n",
    "    A*:ç»Ÿä¸€æˆæœ¬+è´ªå©ª  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c188ec0",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcf276",
   "metadata": {},
   "source": [
    "2.1.Supervised Learning ç›‘ç£å­¦ä¹ \n",
    "    An equation relating input to output\n",
    "    Search through family of possible equations to find one that fits training data well\n",
    "\n",
    "2.1.1.Regressionå›å½’\n",
    "    å•å˜é‡å›å½’é—®é¢˜ï¼ˆä¸€ä¸ªè¾“å‡ºï¼Œå®æ•°å€¼ï¼‰\n",
    "\n",
    "2.1.2.Binary Classification äºŒå…ƒåˆ†ç±»\n",
    "    äºŒå…ƒåˆ†ç±»é—®é¢˜ï¼ˆä¸¤ä¸ªç¦»æ•£ç±»åˆ«ï¼‰\n",
    "\n",
    "2.1.3.Multiclass Classification\n",
    "    å¤šç±»åˆ†ç±»é—®é¢˜ï¼ˆç¦»æ•£ç±»åˆ«ï¼Œ>2 ä¸ªå¯èƒ½çš„å€¼ï¼‰\n",
    "\n",
    "2.2.Unsupervised Learning æ— ç›‘ç£å­¦ä¹ \n",
    "    å­¦ä¹ æ— æ ‡ç­¾æ•°æ®é›†\n",
    "    Clustering èšç±»ï¼šå°†ç›¸ä¼¼çš„æ•°æ®ç‚¹åˆ†ç»„åœ¨ä¸€èµ·\n",
    "\n",
    "2.3.Reinforcement Learning å¼ºåŒ–å­¦ä¹ \n",
    "    ä¸€ç»„ States çŠ¶æ€/ Actions åŠ¨ä½œ/ Rewards å¥–åŠ±\n",
    "    Goal: take actions to change the state so that you receive rewards\n",
    "    You have to explore the environment yourself to gather data as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001099e9",
   "metadata": {},
   "source": [
    "2.4.Decision Trees å†³ç­–æ ‘ï¼ˆsupervised machine learningï¼‰\n",
    "    åº”ç”¨: classification and regression\n",
    "    partition the data into subsets that are increasingly homogeneousåŒè´¨ with respect to the response variable\n",
    "    Feature A may be the most important feature(å®ƒå°†è®­ç»ƒæ ·æœ¬åˆ’åˆ†ä¸ºæ›´æ¥è¿‘å®Œå…¨æ­£é¢æˆ–å®Œå…¨è´Ÿé¢çš„å­é›†ï¼ˆå³æ›´åŒè´¨åŒ–ï¼‰)ï¼Œso check it earlier(å€’ç€ç”»)\n",
    "    Goal:generalizesæ³›åŒ– well from the training data and accurately classifies previously unseen sampleså‡†ç¡®åˆ†ç±»å…ˆå‰æœªè§è¿‡çš„æ ·æœ¬\n",
    "\n",
    "2.4.1.Entropy ç†µ (randomness or uncertainty éšæœºæ€§æˆ–ä¸ç¡®å®šæ€§)\n",
    "    ğ»(âŸ¨p1,Â· Â· Â· , pn âŸ©) = sigma(i=1,n) âˆ’pğ‘–log2ğ‘ğ‘–\n",
    "    maximized when all outcomes are equally likely\n",
    "    minimized when the probability distribution is highly concentrated around a single outcome\n",
    "    å†³ç­–æ ‘é€šè¿‡åœ¨æ¯ä¸ªæ­¥éª¤ä¸­é€‰æ‹©ã€æœ€å°ã€‘ç†µçš„ç‰¹å¾æ¥æ„å»º\n",
    "\n",
    "2.4.2.Minimal Error Pruning æœ€å°é”™è¯¯å‰ªæ\n",
    "    prune branches that do not provide much benefit in classifying the items (aids generalization, avoids overfitting)\n",
    "    Laplace error æ‹‰æ™®æ‹‰æ–¯è¯¯å·®:E= 1âˆ’(n+1)/(N+k)\n",
    "        N = total number of (training) items at the node\n",
    "        n = number of (training) items in the majority class\n",
    "        k = number of classes\n",
    "    å¦‚æœå­èŠ‚ç‚¹çš„å¹³å‡æ‹‰æ™®æ‹‰æ–¯è¯¯å·®è¶…è¿‡çˆ¶èŠ‚ç‚¹ï¼Œåˆ™å‰ªé™¤å­èŠ‚ç‚¹\n",
    "\n",
    "2.4.3.Tree Limitations\n",
    "    high varianceé«˜æ–¹å·®(ä¸ç¨³å®š): 1.arise from a tiny change in the training data, leading to completely different predictions\n",
    "                               2.æ¨¡å‹å€¾å‘äºâ€œè®°å¿†â€è®­ç»ƒæ•°æ®ï¼ˆoverfitting è¿‡æ‹Ÿåˆï¼‰ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ½œåœ¨çš„æ¨¡å¼\n",
    "                               3.ä½æ–¹å·®: æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šæ›´åŠ ç¨³å®šå’Œä¸€è‡´\n",
    "    Suboptimal predictive performance é¢„æµ‹æ€§èƒ½ä¸ä½³: Single trees often fail to achieve strong generalization æ³›åŒ–èƒ½åŠ›\n",
    "    generalization æ³›åŒ– æ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æœªè§è¿‡æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œè€Œä¸ä»…ä»…æ˜¯è®­ç»ƒæ•°æ®\n",
    "    divided into three subsets: training, validation,and test\n",
    "                              1.è®­ç»ƒé›†ï¼šç”¨äºè®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ã€‚\n",
    "                              2.éªŒè¯é›†ï¼šç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°ä¸åŒçš„é…ç½®ï¼ˆè¶…å‚æ•°ï¼‰\n",
    "                              3.æµ‹è¯•é›†ï¼šä¸ºæœ€ç»ˆå†³ç­–æ ‘æ¨¡å‹åœ¨æœªè§è¿‡æ•°æ®ä¸Šæä¾›æ— åè¯„ä¼°ã€‚\n",
    "    Bias åå·®: systematic error ç³»ç»Ÿæ€§è¯¯å·®, ç”¨ç®€å•çš„æ¨¡å‹è¿‘ä¼¼ç°å®é—®é¢˜æ—¶å¼•å…¥çš„\n",
    "        A high bias model makes strong assumptions about the data, leading to underfittingæ¬ æ‹Ÿåˆ\n",
    "    bias-variance tradeoff:å¤æ‚çš„æ¨¡å‹å¯ä»¥å¸®åŠ©æˆ‘ä»¬é¿å…åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰ï¼Œè€Œé™åˆ¶æ¨¡å‹å¤æ‚åº¦å¯ä»¥å¸®åŠ©æˆ‘ä»¬é¿å…è¿‡æ‹Ÿåˆï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "\n",
    "2.4.4.Tree Depth\n",
    "    Shallow trees æµ…æ ‘ç”±äºæ ‘æ²¡æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹æ¥æ•æ‰æ•°æ®çš„å¤æ‚æ€§ï¼Œå› æ­¤ä¼šé­å—é«˜åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰\n",
    "    Deep trees æ·±æ ‘å®¹æ˜“å—åˆ°é«˜æ–¹å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰çš„å½±å“ï¼Œå› ä¸ºæ ‘å¯èƒ½ä¼šä¸ºæ¯ä¸ªæ•°æ®æ ·æœ¬åˆ†é…ä¸€ä¸ªç‹¬ç‰¹çš„è·¯å¾„ï¼Œè€Œä¸æ˜¯å­¦ä¹ ä¸€èˆ¬æ¨¡å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad0483",
   "metadata": {},
   "source": [
    "2.5.Ensemble Learning with Trees åŸºäºæ ‘çš„é›†æˆå­¦ä¹ \n",
    "2.5.1.Bagged Tree è£…è¢‹æ ‘\n",
    "    relies on bootstrapping è‡ªåŠ©é‡‡æ · to create multiple training datasets\n",
    "    bootstrapping: with replacement æœ‰æ”¾å›, sample is the same size è§„æ¨¡ç›¸åŒ as the original dataset\n",
    "        37% out-of-bag (OOB) samples: æœªåŒ…å«åœ¨è‡ªåŠ©é‡‡æ ·ä¸­çš„æ•°æ®ç‚¹\n",
    "    é›†æˆä¸­çš„æ¯ä¸ªæ¨¡å‹éƒ½ä¼šä¸ºæ–°æ ·æœ¬ç”Ÿæˆä¸€ä¸ªé¢„æµ‹ï¼Œæœ€ç»ˆé¢„æµ‹æ˜¯é€šè¿‡the majority vote ruleå¤šæ•°æŠ•ç¥¨è§„åˆ™ï¼ˆç”¨äºåˆ†ç±»ï¼‰æˆ–é€šè¿‡å¹³å‡é¢„æµ‹å€¼ï¼ˆç”¨äºå›å½’ï¼‰æ¥åšå‡ºçš„\n",
    "    Advantages:1.reduces the variance\n",
    "               2.average prediction has lower variance\n",
    "               3.errors(vary in different directions) partially cancel out\n",
    "               4.No separate test set required\n",
    "               5.OOB samples provides an unbiased estimate of performance æ— åçš„æ€§èƒ½ä¼°è®¡\n",
    "    æ¯æ£µå­æ ‘æœ€ç»ˆéƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„,ç„¶è€Œï¼Œè¿™äº›æ ‘å½¼æ­¤ä¹‹é—´ä»ç„¶å­˜åœ¨ä¸€å®šçš„correlatedç›¸å…³æ€§,å› æ­¤ï¼Œè£…è¢‹æ–¹æ³•å®ç°çš„æ–¹å·®å‡å°‘å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›ï¼Œä»ç»Ÿè®¡å­¦çš„è§’åº¦æ¥çœ‹ï¼Œé€šè¿‡åœ¨æ ‘æ„å»ºè¿‡ç¨‹ä¸­å¼•å…¥additional randomnessé¢å¤–çš„éšæœºæ€§ï¼Œå¯ä»¥å‡å°‘é¢„æµ‹å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§\n",
    "\n",
    "2.5.2.Random Forest éšæœºæ£®æ—\n",
    "    æœ€ç»ˆé¢„æµ‹: the majority vote rule\n",
    "    åœ¨æ¯ä¸ªæ ‘çš„åˆ†å‰²ç‚¹ï¼Œç®—æ³•éšæœºé€‰æ‹© k predictors (features) k ä¸ªé¢„æµ‹å™¨ï¼ˆç‰¹å¾ï¼‰ã€‚k = âˆšpï¼Œå…¶ä¸­ p æ˜¯ç‰¹å¾çš„æ€»æ•°\n",
    "    ç„¶åï¼Œæ ‘ä»…ä»è¿™äº› k ä¸ªç‰¹å¾ä¸­é€‰æ‹©æœ€ä½³åˆ†å‰²\n",
    "    è¿™ç§éšæœºæ€§å‡å°‘äº†æ ‘ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆè¿™æ˜¯è£…è¢‹æ ‘çš„é—®é¢˜ï¼‰\n",
    "    ä¸è£…è¢‹æ³•ç›¸æ¯”ï¼Œéšæœºæ£®æ—åœ¨é€æ£µæ ‘çš„åŸºç¡€ä¸Šæ›´å…·æœ‰è®¡ç®—æ•ˆç‡ï¼Œå› ä¸ºæ ‘æ„å»ºè¿‡ç¨‹ä»…éœ€åœ¨æ¯ä¸ªåˆ†è£‚ç‚¹è¯„ä¼°a fraction of the original featuresåŸå§‹ç‰¹å¾çš„ä¸€éƒ¨åˆ†ï¼Œå°½ç®¡éšæœºæ£®æ—é€šå¸¸éœ€è¦more treesæ›´å¤šçš„æ ‘\n",
    "    é€‰æ‹©éšæœºæ£®æ—å’Œ Bagging ä¸­æ ‘çš„æ•°é‡ï¼ˆmï¼‰ï¼š1.Variance reduction æ–¹å·®å‡å°‘: å¢åŠ æ›´å¤šçš„æ ‘å¯ä»¥å‡å°‘æ–¹å·®ï¼Œä½¿é¢„æµ‹æ›´åŠ ç¨³å®š\n",
    "                                      2.Constraints çº¦æŸæ¡ä»¶: å½“å¢åŠ  m æ—¶ï¼Œè®­ç»ƒæ—¶é—´ã€å†…å­˜ä½¿ç”¨å’Œè¿‡æ‹Ÿåˆæ˜¯ä¸»è¦çš„é™åˆ¶å› ç´ \n",
    "                                      3.Test error behavior æµ‹è¯•è¯¯å·®è¡Œä¸º: æµ‹è¯•è¯¯å·®é€šå¸¸éšç€ m çš„å¢åŠ è€Œå•è°ƒé€’å‡â€”â€”èµ·åˆè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ï¼Œåœ¨è¶³å¤Ÿå¤šçš„æ ‘ä¹‹åå‡ ä¹ä¿æŒæ’å®š\n",
    "\n",
    "2.5.3.Boosting Trees(AdaBoost)æå‡æ ‘\n",
    "    æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒAdaBoost æ ¹æ®å½“å‰çš„åŠ æƒæ•°æ®ç‚¹é€‰æ‹©æœ€ä½³åˆ†ç±»å™¨\n",
    "    åœ¨ k æ¬¡è¿­ä»£ä¸­è¢«é”™è¯¯åˆ†ç±»çš„æ•°æ®ç‚¹åœ¨(k+1)æ¬¡è¿­ä»£ä¸­è·å¾—higher weightsæ›´é«˜çš„æƒé‡\n",
    "    å› æ­¤ï¼Œéš¾ä»¥åˆ†ç±»çš„æ ·æœ¬ä¼šé€æ¸è·å¾—è¶Šæ¥è¶Šå¤§çš„æƒé‡\n",
    "    è¿™ä¸ªè¿‡ç¨‹ç¡®ä¿æ¯æ¬¡è¿­ä»£éƒ½ä¸“æ³¨äºå­¦ä¹ æ•°æ®çš„æŸä¸ªä¸åŒæ–¹é¢\n",
    "    æœ€åï¼Œè¿™äº›weighted classifiersåŠ æƒåˆ†ç±»å™¨çš„åºåˆ—è¢«ç»„åˆæˆä¸€ä¸ªé›†æˆï¼Œäº§ç”Ÿä¸€ä¸ªå¼ºå¤§çš„æ•´ä½“æ¨¡å‹\n",
    "    Algorithm:è®¡ç®—\n",
    "\n",
    "\n",
    "2.5.4.å¯¹æ¯”\n",
    "    è£…è¢‹æ³•é€šè¿‡åœ¨è‡ªåŠ©é‡‡æ ·ä¸Šè®­ç»ƒå¤šä¸ªæ ‘å¹¶èšåˆå®ƒä»¬çš„é¢„æµ‹æ¥é™ä½high varianceé«˜æ–¹å·®\n",
    "    éšæœºæ£®æ—é€šè¿‡åœ¨è®­ç»ƒä¸­æ·»åŠ randomnesséšæœºæ€§ï¼ˆä¾‹å¦‚ï¼Œåœ¨æ¯ä¸ªåˆ†è£‚æ—¶é€‰æ‹©éšæœºç‰¹å¾å­é›†ï¼‰è¿›ä¸€æ­¥variance reductionå‡å°‘æ–¹å·®.æ ‘æ˜¯in parallelå¹¶è¡Œä¸”åŒç­‰æƒé‡è®­ç»ƒçš„ï¼Œè¿™èƒ½æœ‰æ•ˆå‡å°‘æ–¹å·®ï¼Œä½†å¹¶ä¸èƒ½æ˜¾è‘—reduce biaså‡å°‘åå·®\n",
    "    æå‡æ–¹æ³•é€šè¿‡sequentiallyé¡ºåºè®­ç»ƒæ ‘æ¥å‡å°‘bias and varianceåå·®å’Œæ–¹å·®ï¼Œå…¶ä¸­æ¯æ£µæ–°æ ‘ä¸“æ³¨äºçº æ­£å‰ä¸€æ£µæ ‘çš„é”™è¯¯ï¼Œå¹¶æ ¹æ®å…¶æ€§èƒ½å¯¹æ ‘è¿›è¡ŒåŠ æƒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45199a53",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93278383",
   "metadata": {},
   "source": [
    "3.1.Artificial Neural Networksäººå·¥ç¥ç»ç½‘ç»œ\n",
    "    This model consists of many interconnected processing units (neurons)ç¥ç»å…ƒ that work in parallel to accomplish a global task\n",
    "    model relationships between inputs and outputs or to discover patterns in data\n",
    "    Learning occurs by adapting weights, architecture, and activation/transfer functions to improve performance\n",
    "    Characterized by: Number of neurons, Interconnection architecture, Weight values, Activation and transfer functions\n",
    "\n",
    "3.1.1.model of a neuron\n",
    "    An extra constant w0 called the biasåå·® is also added\n",
    "\n",
    "3.1.2.Neural Networks are made up of nodes which have:\n",
    "    Input edges, each with some weight\n",
    "    Output edges (with weights)\n",
    "    An activation level (a function of the inputs)\n",
    "        Weights can be positive or negative and may change overtime (learning).\n",
    "        The input function is the weighted sum of the activation levels of inputs.\n",
    "        The activation level is a non-linear transfer function (activation function), g, of this input.\n",
    "        z= g(s)= g(ğ‘¤0 + Ïƒğ‘– ğ‘¤ğ‘–ğ‘¥ğ‘–) å¿…é¡»å¤§äº0æ‰æ˜¯1\n",
    "\n",
    "3.2.Perceptronæ„ŸçŸ¥å™¨\n",
    "    An artificial neuron with step transfer functioné˜¶è·ƒä¼ é€’å‡½æ•°(é›¶ç‚¹å·¦å³0,1) is called a Perceptron\n",
    "    The bias (w0) was thought of as a kind of thresholdé˜ˆå€¼. If the combination -Ïƒğ‘– ğ‘¤ğ‘–ğ‘¥ğ‘– is less than this threshold, the neuron would \"fire\" (its output would be 1)\n",
    "    The higher the bias, the more likely the neuron is to fire\n",
    "    Later on, alternative transfer functions were introduced which are continuous and (mostly) differentiable\n",
    "3.2.1.hyperplane\n",
    "    The weights and bias of a Perceptron define a hyperplaneè¶…å¹³é¢ that divides the input space into two regions\n",
    "        For inputs on one side of the hyperplane, the output is 0\n",
    "        For inputs on the other side, the output is 1\n",
    "    Functions that can be computed in this way are called linearly separableçº¿æ€§å¯åˆ†. With this structure, a perceptron (artificial neuron) can learn any linear relationshipä»»ä½•çº¿æ€§å…³ç³»\n",
    "3.2.2.Application\n",
    "    Limitation: What happens if the data is not linearly separable\n",
    "    AND, OR, and NOT become linearly separable,but XOR are not\n",
    "\n",
    "3.3.Multi Layer Perceptronå¤šå±‚æ„ŸçŸ¥å™¨\n",
    "    compute XOR, one approach is to rewrite it in terms of linearly separable functions such as AND, OR, and NOR, and then arrange several perceptronå¤šä¸ªæ„ŸçŸ¥å™¨æ’åˆ— into a network that combines these functions appropriately\n",
    "    However, in practice, we usually deal with raw dataåŸå§‹æ•°æ® rather than explicit logical expressions\n",
    "    perceptron learning algorithmâ€”that can learn the weights of a neural networkäº†è§£ç¥ç»ç½‘ç»œçš„æƒé‡ from a set of training examples\n",
    "\n",
    "3.4.Learning with Gradient Descent and Backpropagationé€šè¿‡æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­è¿›è¡Œå­¦ä¹ \n",
    "    to optimize over a family of continuous and differentiable functions\n",
    "    define an error functionè¯¯å·®å‡½æ•° (also called a loss function or cost function) ğ¸as half the sum, over all input items, of the square of the difference between the actual output ğ‘§ğ‘–and the target output ğ‘¡ğ‘–\n",
    "    goal is to find the minimum of the error function ğ¸æ‰¾åˆ°è¯¯å·®å‡½æ•° E çš„æœ€å°å€¼, and minimum of a function can be calculated through its derivativeå¯¼æ•°\n",
    "    We can use multi-variable derivative to adjust the weights in such a way as to take us in the steepest downhill direction. w â† wâˆ’ Î· ğğ‘¬/ğğ’˜ , Î· is called the learning rateå­¦ä¹ ç‡\n",
    "    If we use the step function as the transfer function, the error landscape is not smooth; it consists almost entirely of flat regions and \"shoulders,\" with occasional discontinuous jumps.\n",
    "    For a single-layer perceptron, this was not a problem, but for networks with two or more layers, it becomes a major obstacle.\n",
    "    To apply gradient descent successfully, neural networks needed to be redesigned so that the function from input to output would be smooth and differentiableå¹³æ»‘ä¸”å¯å¾®\n",
    "3.4.1.Learning rate identify the step sizeå­¦ä¹ ç‡ç¡®å®šæ­¥é•¿\n",
    "    The key idea is to replace the (discontinuous) step function with a differentiable function, such as the sigmoid or hyperbolic tangent g(s)= ğŸ/ğŸ+ğ’†^(âˆ’ğ’”)\n",
    "    We now describe how to compute the partial derivatives of the loss function with respect to each weightæŸå¤±å‡½æ•°ç›¸å¯¹äºæ¯ä¸ªæƒé‡çš„åå¯¼æ•°\n",
    "    For illustration, we consider a two-layer neural network with sigmoid activationæ¿€æ´» sigmoid çš„ä¸¤å±‚ç¥ç»ç½‘ç»œ at the hidden layer, as shown in the diagram\n",
    "    ğ‘¥ğ‘– are the inputs, ğ‘¦ğ‘– are the hidden units, ğ‘¤ğ‘–ğ‘— and ğ‘£ğ‘– are the weights, and ğ‘ğ‘– and ğ‘ are the biases\n",
    "    Chain Rule(ä¼šè€ƒ)\n",
    "\n",
    "3.4.2.Backpropagationåå‘ä¼ æ’­\n",
    "    Forward passå‰å‘ä¼ é€’: apply inputs to the â€œlowest layerâ€ and feed activations forward to get output\n",
    "    Calculate errorè®¡ç®—è¯¯å·®: difference between desired output and actual output \n",
    "    Backward passå‘åä¼ é€’: Propagate errors back through the network to adjust weights\n",
    "    Since our prediction is greater than the target value, we need to decrease the weighté™ä½æƒé‡ in order to reduce the prediction in the next iterations\n",
    "    As we propagate back to the weights in the earlier layers, the amount of adjustment (decrement) becomes smallerå˜å°. For example, the change in ğ‘¤13 is more significant than the change in ğ‘¤11\n",
    "\n",
    "3.5.Neural Networks Designç¥ç»ç½‘ç»œè®¾è®¡\n",
    "\n",
    "3.5.1.Exhaustive Analysis of the Systemå¯¹ç³»ç»Ÿçš„è¯¦å°½åˆ†æ\n",
    "    Is a neural network really the best solution for this problem? Do I have the necessary requirements?ç¥ç»ç½‘ç»œçœŸçš„æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æœ€ä½³è§£å†³æ–¹æ¡ˆå—ï¼Ÿæˆ‘æœ‰å¿…è¦çš„è¦æ±‚å—ï¼Ÿ\n",
    "    Neural Networks: The second-best optionç¥ç»ç½‘ç»œï¼šç¬¬äºŒå¥½çš„é€‰æ‹©\n",
    "        Neural networks are highly data-sensitive and usually require large datasets, since they need to learn a large number of parameters (ğ‘¤ğ‘–)\n",
    "        Collecting and preparing such data can be costly and time-consuming\n",
    "\n",
    "3.5.2.Preprocessingé¢„å¤„ç†\n",
    "    What steps should I take before feeding data into the networkåœ¨å°†æ•°æ®è¾“å…¥ç½‘ç»œä¹‹å‰ï¼Œæˆ‘åº”è¯¥é‡‡å–å“ªäº›æ­¥éª¤ï¼Ÿ\n",
    "    Dataæ•°æ®:\n",
    "        A neural network is essentially a black-box model designed for interpolation (with no guarantee of good performance in extrapolation).\n",
    "        Therefore, its effectiveness strongly depends on the quality and quantity of the data available.\n",
    "    Qualityè´¨é‡:\n",
    "        This refers to how well the available data represents the underlying function being approximated.\n",
    "    Quantityæ•°é‡:\n",
    "        Only with a sufficiently large dataset can we expect to correctly identify the parameters (weights) of a neural model.\n",
    "        If the available data is insufficient, data augmentation techniques can be used to expand it\n",
    "3.5.2.1.Data cleaning:\n",
    "    Detect and, if possible, eliminate outliers, empty values, etc. It might also help to detect correlations between variables.\n",
    "    Normalisation of variables:\n",
    "        Xn = (X- Xmin)/ (Xmax-Xmin); Xn âˆˆ [0,1] or Xn = 2*(X-Xmin)/(Xmax-Xmin) â€“ 1; Xn âˆˆ [-1,1]\n",
    "    It is necessary to perform the corresponding denormalization at the output stageè¾“å‡ºé˜¶æ®µ\n",
    "3.5.2.2.why data normalizationä¸ºä»€ä¹ˆè¦è¿›è¡Œæ•°æ®å½’ä¸€åŒ–\n",
    "    1. To ensure features are comparable in scale ç¡®ä¿åŠŸèƒ½åœ¨è§„æ¨¡ä¸Šå…·æœ‰å¯æ¯”æ€§\n",
    "        Many datasets include features with very different ranges (e.g., age in years vs. income in dollars).\n",
    "        Without normalization, features with larger scales can dominate smaller ones in distance-based or gradient-based models.\n",
    "    2. To improve training stability and speed æé«˜è®­ç»ƒç¨³å®šæ€§å’Œé€Ÿåº¦\n",
    "        Gradient descent converges faster when features are on a similar scale.\n",
    "        If not normalized, the loss landscape can become very steep in some directions and flat in others.\n",
    "\n",
    "3.5.3.Design of the Neural Network ç¥ç»ç½‘ç»œçš„è®¾è®¡\n",
    "    What should the architecture of my network look like? (e.g., number of layers, number of neurons per layer, choice of activation functions, and other hyperparameters). æˆ‘çš„ç½‘ç»œæ¶æ„åº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ï¼Ÿï¼ˆä¾‹å¦‚ï¼Œå±‚æ•°ã€æ¯å±‚ç¥ç»å…ƒæ•°ã€æ¿€æ´»å‡½æ•°çš„é€‰æ‹©å’Œå…¶ä»–è¶…å‚æ•°ï¼‰\n",
    "    Rule of thumbç»éªŒæ³•åˆ™: Nh should lead to a number of parameters (weights) Nw that: Nw < (Number of samples) / 10\n",
    "        The number of weights Nw of a MLP, with Ni neurons in its input layer, a hidden layer with Nh neurons, and No neurons in the output layer is: Nw = (Ni+1)*Nh+(Nh+1)*No\n",
    "    Conclusion: more parameters and deeper networks do not lead to better a performance necessarily.\n",
    "    There should be a proportion between your dataset size, problem complexity, etc. and number of parameters æ•°æ®é›†å¤§å°ã€é—®é¢˜å¤æ‚æ€§ç­‰ä¸å‚æ•°æ•°é‡ä¹‹é—´åº”è¯¥æœ‰ä¸€å®šæ¯”ä¾‹\n",
    "    In MLPs is demonstrated that using one hidden layer with a proper number of neurons is sufficient to approximate any non-linear function with an arbitrary precision degree (Universal Approximation Theorem)åœ¨ MLP ä¸­ï¼Œè¯æ˜ä½¿ç”¨å…·æœ‰é€‚å½“æ•°é‡ç¥ç»å…ƒçš„éšè—å±‚å°±è¶³å¤Ÿä»¥ä»»æ„ç²¾åº¦åº¦è¿‘ä¼¼ä»»ä½•éçº¿æ€§å‡½æ•°ï¼ˆé€šç”¨é€¼è¿‘å®šç†ï¼‰ã€‚\n",
    "    Activation functionsæ¿€æ´»å‡½æ•°:\n",
    "        A usual criterion is to use sigmoid functions or ReLUs in the hidden layer and linear functions in the output. However, sigmoids or softmax can also be used in the output.\n",
    "\n",
    "3.5.4.Training\n",
    "    What happens during the training phase?\n",
    "    Training a neural network is a hard process due to the complexity of the error function solution space, which can have numerous local minima, minimax points, etc\n",
    "    There are three main problems that can arise during training:\n",
    "        Biasåå·®\n",
    "        Overparameterizationè¿‡åº¦å‚æ•°åŒ–\n",
    "        Overfittingè¿‡æ‹Ÿåˆ\n",
    "    The latter two might affect the network's ability to generalize (high variance)æ³›åŒ–èƒ½åŠ›ï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "3.5.4.1.Bias\n",
    "    refers to the systematic error introduced by approximating a real-world problem (which may be very complex) with a simpler model.åå·®æ˜¯æŒ‡é€šè¿‡ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹è¿‘ä¼¼ç°å®ä¸–ç•Œçš„é—®é¢˜ï¼ˆå¯èƒ½éå¸¸å¤æ‚ï¼‰è€Œå¼•å…¥çš„ç³»ç»Ÿè¯¯å·®ã€‚\n",
    "    A high bias model makes strong assumptions about the data, leading to underfitting.é«˜åå·®æ¨¡å‹å¯¹æ•°æ®åšå‡ºå¼ºçƒˆçš„å‡è®¾ï¼Œå¯¼è‡´æ‹Ÿåˆä¸è¶³ã€‚\n",
    "    It canâ€™t capture the true complexity of the underlying relationshipå®ƒæ— æ³•æ•æ‰æ½œåœ¨å…³ç³»çš„çœŸæ­£å¤æ‚æ€§ã€‚\n",
    "    To Decrease Bias:\n",
    "        One way to reduce bias is to run multiple training processes starting from different randomly chosen initial weights (e.g., 20 or more attempts). This increases the chance of reaching a better local minimum.\n",
    "        Another approach is to increase the number of neurons in the hidden layer, which allows the model to better capture the complexity of the problem.\n",
    "            However, there is a trade-off: adding too many neurons can lead to high variance and overparameterization, causing the model to overfitæ·»åŠ è¿‡å¤šçš„ç¥ç»å…ƒä¼šå¯¼è‡´é«˜æ–¹å·®å’Œè¿‡åº¦å‚æ•°åŒ–ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦æ‹Ÿåˆã€‚\n",
    "3.5.4.2.Overfittingè¿‡æ‹Ÿåˆ\n",
    "    A model is considered overparameterized when it has more trainable parameters than the available training data can uniquely determine.\n",
    "    In simpler terms, the model has too many parameters relative to the size or complexity of the dataset.\n",
    "    As a result, it becomes powerful enough to memorizeè®°ä½ the training data (including noise) rather than learning the underlying general patterns\n",
    "    The neural network is trained by presenting it with the input and target values for all items in the training set\n",
    "    After completing the learning procedure, it must then predict the outputs for items in the test set\n",
    "    The goal is to accurately predict the target values for the test set based on the input attributes.\n",
    "    A common mistake to avoid is building a model that fits the training data very well but performs poorly on unseen test dataâ€”this problem is known as overfitting.è¿‡åº¦æ‹Ÿåˆ\n",
    "    In contrast, a model that achieves high accuracy on both the training and test sets is said to have good generalizationæ¦‚æ‹¬æ€§\n",
    "    To determine the optimal model parameters, the dataset is often divided into Training, Validation, and Test (generalization) setsä¸ºäº†ç¡®å®šæœ€ä½³æ¨¡å‹å‚æ•°ï¼Œæ•°æ®é›†é€šå¸¸åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•ï¼ˆæ³›åŒ–ï¼‰é›†ã€‚\n",
    "    Typically, as the number of hidden nodes increases, both the training and test errors initially decrease.\n",
    "    However, beyond a certain point, the training error may continue to decrease while the test error plateaus or even slightly increases. The approximate number of hidden nodes at which the test error is minimal is likely to achieve the best generalization performanceæµ‹è¯•è¯¯å·®æœ€å°çš„éšè—èŠ‚ç‚¹çš„è¿‘ä¼¼æ•°é‡å¯èƒ½ä¼šå®ç°æœ€ä½³çš„æ³›åŒ–æ€§èƒ½\n",
    "3.5.4.3.Conclusion:\n",
    "    Increasing the number of neurons can help reduce bias (underfitting), while limiting the number of neurons helps prevent overfitting (high variance). This balance reflects the well-known biasâ€“variance trade-off.å¢åŠ ç¥ç»å…ƒæ•°é‡æœ‰åŠ©äºå‡å°‘åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰ï¼Œè€Œé™åˆ¶ç¥ç»å…ƒæ•°é‡æœ‰åŠ©äºé˜²æ­¢è¿‡åº¦æ‹Ÿåˆï¼ˆé«˜æ–¹å·®ï¼‰ã€‚è¿™ç§å¹³è¡¡åæ˜ äº†ä¼—æ‰€å‘¨çŸ¥çš„åå·®-æ–¹å·®æƒè¡¡ã€‚\n",
    "    In addition to adjusting the network size, there are other techniques available to address\n",
    "underfitting and overfitting, such as regularization, early stopping, and data augmentation.\n",
    "\n",
    "3.5.5.Testing and Evaluationæµ‹è¯•å’Œè¯„ä¼°\n",
    "    How should I evaluate the performance of my network\n",
    "    To test the generalization capability of the network, performance is evaluated on the test setåœ¨æµ‹è¯•é›†\n",
    "    Some common loss functions:\n",
    "        Mean Squared Error (MSE):\n",
    "        Mean Absolute Error (MAE):\n",
    "        Cross-Entropy (Binary Cross-Entropy (for 2 classes))\n",
    "\n",
    "3.6.Deep Learning æ·±åº¦å­¦ä¹ \n",
    "    If we denote the first layer as ğ‘“ 1 , the second layer is ğ‘“ 2 , and so on. The total number of layers defines the depthæ·±åº¦ of the model, which is why this approach is known as deep learningæ·±åº¦å­¦ä¹ \n",
    "3.6.1.depth\n",
    "    The depth of a model is defined as the total number of layers with learnable parameters, excluding theinput layer.ä¸åŒ…æ‹¬è¾“å…¥å±‚\n",
    "    Deeper networks can typically approximate more complex functions, while shallower models have fewer layers and are limited to approximating simpler functions.\n",
    "\n",
    "Deep learning is based on the philosophy of connectionism:è¿æ¥ä¸»ä¹‰\n",
    "    while an individual biological neuron is not particularly intelligent, a large population of neurons or features acting together can exhibit intelligent behavior\n",
    "    It is important to emphasize that the number of neurons must be large.ç¥ç»å…ƒçš„æ•°é‡å¿…é¡»å¾ˆå¤§\n",
    "    One of the key factors behind the dramatic improvement in neural network accuracy and the complexity of tasks they can handleâ€”from the 1980s to todayâ€”is the significant increase in network size\n",
    "\n",
    "    Deep learning refers to artificial neural networks with multiple layers that automatically learn\n",
    "patterns and representations from data\n",
    "    What makes a network â€œdeepâ€ is the presence of many layers of neurons, not just one or two. A shallow networkæµ…å±‚ç½‘ç»œ might have only a single hidden layer, whereas a deep networkæ·±åº¦ç½‘ç»œ can have hundreds or even thousands of layers\n",
    "\n",
    "    Universal Approximation Theoremé€šç”¨é€¼è¿‘å®šç†\n",
    "        One layer with many neurons:\n",
    "            wide hidden layeréå¸¸å®½çš„éšè—å±‚,\n",
    "            but it is still shallowæ·±åº¦è¾ƒä½ \n",
    "            computationally inefficient and does not capture hierarchical representations effectively (low precision)\n",
    "        Many layers, each with one neuron:\n",
    "            This network is extremely deep but very narrow.éå¸¸æ·±ï¼Œä½†éå¸¸ç‹­çª„\n",
    "            It qualifies as deep learningæ·±åº¦å­¦ä¹  because the depth (number of layers) is enormous.\n",
    "            However, with only one neuron per layer, the networkâ€™s expressive power is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c36d9",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdedcd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b38c218e",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feeb715",
   "metadata": {},
   "source": [
    "5.1.Optimisation method ä¼˜åŒ–æ–¹æ³•\n",
    "    dvantages of gradient descent:æ¢¯åº¦ä¸‹é™çš„ä¼˜ç‚¹\n",
    "        Easy implementation.\n",
    "        Standard method that works generally well.\n",
    "    Drawbacks of gradient descent:æ¢¯åº¦ä¸‹é™çš„ç¼ºç‚¹\n",
    "        Slow and inefficient.\n",
    "        It might get stuck on local minima leading to suboptimal results\n",
    "    Improvements to gradient descent:æ¢¯åº¦ä¸‹é™çš„æ”¹è¿›\n",
    "        Momentum åŠ¨é‡: Add percentage of last movement to the actual one.\n",
    "        Stochastic batch (SGD) éšæœºæ‰¹æ¬¡: Estimate gradient using subsample set.\n",
    "        Adaptable estimation (Adam) é€‚åº”ä¼°è®¡: Adapt the learning rate for each weight of the neural network\n",
    "    The option to elegantly and efficiently calculate the gradient allows us to handle the optimisation problem using the full range of optimisation methods provided by nonlinear optimisation systems\n",
    "\n",
    "5.2.Asymptotic complexity æ¸è¿‘å¤æ‚åº¦\n",
    "    Complexity å¤æ‚æ€§: The complexity of an algorithm is a measure of the amount of resources it consumes.\n",
    "    Resource èµ„æº:\n",
    "        Time\n",
    "        Space\n",
    "        Memory\n",
    "        Drive\n",
    "\n",
    "5.3.Classes of problems é—®é¢˜ç±»åˆ«\n",
    "5.3.1.Class P:\n",
    "        A P problem can be solved in polynomial time in a deterministic computer.\n",
    "        The class P comprises problems that can be solved quickly.\n",
    "        Examples: Quicksort, binary search, matrix multiplication.\n",
    "5.3.2.Class NP:\n",
    "        An NP problem cannot be solved in a polynomial time using a deterministic computer (intractable problem).\n",
    "        The class NP comprises problems whose solutions can be verified quickly (PâŠ†NP).\n",
    "        Examples: subsets addition, Sudoku, TSP.\n",
    "5.3.3.Class NP-complete:\n",
    "        A class of problems for which it is unknown if they are tractable.\n",
    "        No one has found polynomial algorithms for any of them.\n",
    "        Some problems closely related to tractable problems.\n",
    "        All known algorithms for NP-complete problems require exponential time in relation to the size of the input.\n",
    "5.3.4.algorithms to solve an NP-complete problem\n",
    "5.3.4.1.Approximation è¿‘ä¼¼:\n",
    "        An algorithm that quickly finds a solution that may not be optimal but falls within a certain range of error. In some cases, finding a good approximation is sufficient to solve the problem, but not all NP-complete problems have good approximation algorithms.\n",
    "5.3.4.2.Heuristics and Metaheuristics å¯å‘å¼å’Œå…ƒå¯å‘å¼:\n",
    "        An algorithm that performs reasonably well in many cases. They are generally fast, but there is no measure of the quality of the answer.\n",
    "5.3.4.3.Genetic Algorithms é—ä¼ ç®—æ³•:\n",
    "        Algorithms that improve possible solutions until finding one that is possibly close to the optimum. There is also no guarantee of the quality of the answer.\n",
    "\n",
    "5.4.Search spaceæœç´¢ç©ºé—´\n",
    "    Feasible solution: is in the feasible region of the problem.\n",
    "    Solution space S and objective function f.\n",
    "    The optimisation problem O(S, f) is solved by determining an optimal solution, i.e., a feasible solution x0 âˆˆ S / f(x) â‰¤ f(x0 ) â±¯ x âˆˆ S.\n",
    "    Constraints of the problem reduce the universe of solutions U, then X âŠ† U, also called feasible region.\n",
    "\n",
    "5.4.1.Neighbourhood search procedures é‚»é‡ŒæœæŸ¥ç¨‹åº:\n",
    "    Transformations or movements from the current solution.\n",
    "        Generate an initial solution.\n",
    "        Iteratively modify it until a stopping criterion.\n",
    "        Solutions are evaluated while traversing.\n",
    "    Possible movements create a neighbourhood.\n",
    "    Feasible movements are those that provide a feasible solution.\n",
    "\n",
    "5.4.2.Constraints çº¦æŸ:\n",
    "    Can be strong (must be satisfied) or weak (recommended to be satisfied).\n",
    "        Example: In course scheduling, a strong constraint is that classes should not overlap, while a weak constraint is that there should be no classes after 4pm.\n",
    "\n",
    "5.4.3.Restricted exploration of the feasible region within the search space æœç´¢ç©ºé—´å†…å¯è¡ŒåŒºåŸŸçš„æœ‰é™æ¢ç´¢:\n",
    "    Advantages: Infeasible solutions are not evaluated. The algorithms ensure obtaining a feasible solution.\n",
    "    Disadvantages: The search can be inefficient if restricted only to the feasible region. Optimal solutions may be located near the boundary and difficult to reach.\n",
    "\n",
    "5.4.4.Complete exploration of the solution space å®Œæ•´æ¢ç´¢è§£å†³æ–¹æ¡ˆç©ºé—´:\n",
    "    Advantages: The exploration of the search space is more effective.\n",
    "    Disadvantages: Time is spent evaluating infeasible solutions. There is a possibility of returning an infeasible solution as the final output of the algorithm.\n",
    "\n",
    "5.4.5.Three strategies for restricted exploration of the feasible region within the search space:\n",
    "    Rejection strategies æ‹’ç»ç­–ç•¥: Any infeasible solution generated during the search is directly ignored.\n",
    "    Repair strategies ä¿®å¤ç­–ç•¥: A repair operator is applied to each infeasible solution generated to transform it into a feasible solution. This strategy is often based on heuristics.\n",
    "    Preservation strategies ä¿å­˜ç­–ç•¥: Both the representation scheme and the operators are specifically designed for the problem in a way that ensures the feasibility of generated solutions. It requires more design effort and are problem-specific.\n",
    "\n",
    "5.4.6.Complete exploration of the solution space å®Œæ•´æ¢ç´¢è§£å†³æ–¹æ¡ˆç©ºé—´:\n",
    "    The most common scheme for complete exploration of the solution space is penalty-based strategies:\n",
    "        A penalty function is added to the original unconstrained objective function: Min f'(x) = f(x) + wÂ·P(x)\n",
    "        where P(x) is a penalty function and w is a weighting coefficient (intensify/diversify).\n",
    "        P(x) takes a value of 0 when the solution x is feasible. Otherwise, the greater the degree of constraint violation, the larger the value of P\n",
    "\n",
    "5.5.Memoryless and memory-based metaheuristics æ— è®°å¿†å’ŒåŸºäºè®°å¿†çš„å…ƒå¯å‘å¼\n",
    "5.5.1.Metaheuristics å…ƒå¯å‘å¼\n",
    "    Metaheuristics provide strategies for solving a problem by conducting a search over the space of possible solutions.\n",
    "    The solution representation must include all the necessary information for their identification and evaluation.\n",
    "    A search over a space involves generating a sequence of points in the space, where each point is obtained from the previous one through a series of transformations or movements.\n",
    "    The goal of search-based metaheuristics is to provide guidelines for obtaining paths that yield high-quality solutions while also ensuring adequate effciency\n",
    "5.5.1.1.Memoryless metaheuristics æ— è®°å¿†å…ƒå¯å‘å¼: \n",
    "    do not use or maintain any explicit memory of past search information. They rely solely on the current solution and its neighborhood to make decisions about the next search move. These metaheuristics typically focus on exploration by using randomized or stochastic search techniques.\n",
    "5.5.1.2.Memory-based metaheuristics åŸºäºè®°å¿†çš„å…ƒå¯å‘å¼: \n",
    "    are algorithms that use past information or historical data to guide the search process. They remember and store certain aspects of the search, such as the best solutions found so far or promising regions in the solution space. This memory allows them to make informed decisions and adapt their search strategy based on past experience\n",
    "5.5.1.3.Simulated annealing æ¨¡æ‹Ÿé€€ç« è¦è€ƒï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼\n",
    "    is a probabilistic optimisation algorithm inspired by the annealing process in metallurgy. It is used to find near-optimal solutions for combinatorial optimisation problems.\n",
    "5.5.1.4.Tabu search Tabu æœç´¢\n",
    "is an algorithm used for solving optimisation problems. It is based on the concept of maintaining a tabu list, which keeps track of recently visited solutions to prevent cycling and encourage exploration.\n",
    "\n",
    "5.6.Population-based method åŸºäºäººå£çš„æ–¹æ³•\n",
    "    Operate on a population of candidate solutions rather than a single solution. The population is typically initialized randomly or using heuristic techniques.\n",
    "    Multiple solutions are evaluated simultaneously, allowing for the exploration of the search space more efficiently.\n",
    "        Advantages ä¼˜ç‚¹: ability to simultaneously explore multiple regions of the search space, promoting diversity and preventing premature convergence to suboptimal solutions.\n",
    "        Disadvantages ç¼ºç‚¹: it may require careful parameter tuning and can be computationally demanding due to the population size and iterative nature of the algorithms.\n",
    "    Examples of bio-inspired population-based methods include ant colony optimisation, black hole algorithm, particle swarm optimisation, and genetic algorithms.\n",
    "\n",
    "5.6.1.Swarm optimisation ç¾¤ä½“ä¼˜åŒ–\n",
    "    refers to a family of nature-inspired optimisation algorithms that mimic the collective behaviour of decentralised, self-organised systems found in nature (e.g., bird flocks, fish schools, or ant colonies) to find optimal or near-optimal solutions to complex problems.\n",
    "    The main idea is that a population (swarm) of simple agents (particles, ants, bees, etc.) explores the search space collaboratively. Each agent follows simple rules based on its own experience and that of its neighbours, and through many iterations, the swarm converges toward good/reasonable solutions.\n",
    "    The main concepts of swarm optimisation are:\n",
    "        Population-based åŸºäºäººå£: Many candidate solutions evolve simultaneously.\n",
    "        Decentralised å»ä¸­å¿ƒåŒ–: No single agent controls the process, so intelligence emerges from interaction.\n",
    "        Stochastic éšæœºæŒ‡æ ‡: Uses randomness to explore the search space and avoid local minima.\n",
    "        Adaptive è‡ªé€‚åº”: Agents adjust their behaviour based on feedback.\n",
    "    Some warm optimisation algorithms:\n",
    "        Particle Swarm Optimisation (PSO) ç²’å­ç¾¤ä¼˜åŒ–: Inspired by bird flocking. Each particle adjusts its position based on its own best position and the swarmâ€™s best-known position.\n",
    "        Ant Colony Optimisation (ACO) èšç¾¤ä¼˜åŒ–: Inspired by how ants find shortest paths. Ants deposit pheromones that guide others toward better solutions.\n",
    "        Artificial Bee Colony (ABC) äººå·¥èœ‚ç¾¤: Based on how bees search for food sources and share information.\n",
    "    Applications: function optimisation, robotics path planning, scheduling and resource allocation, neural network training, feature selection in machine learning.\n",
    "\n",
    "5.6.2.Genetic algorithms é—ä¼ ç®—æ³•\n",
    "    Based on Darwinâ€™s evolution theory.\n",
    "    â€œOne general law, leading to the advancement of all organic beings, namely, multiply, vary, let the strongest live and the weakest die.â€ Charles Darwin.\n",
    "    Stochastic search éšæœºæœç´¢ technique based on the mechanisms of natural selection and natural genetics.\n",
    "    Use analogies ç±»æ¯” of natural selection to develop better solutions.\n",
    "    Widely used in problems of nonlinear and high-dimensional optimis\n",
    "    GA model the process of evolution as a sequence of changes in genes, with solutions analogous to chromosomes.\n",
    "    The search space is explored by applying transformations to candidate solutions, just as observed in living organisms: crossover, mutation, and selection\n",
    "    Terminology used in genetic algorithms é—ä¼ ç®—æ³•ä¸­ä½¿ç”¨çš„æœ¯è¯­:\n",
    "\n",
    "5.6.2.1.Three main operators: crossover, mutation, and selection ä¸‰ä¸ªä¸»è¦ç®—å­ï¼šäº¤å‰ã€çªå˜å’Œé€‰æ‹©\n",
    "        Genetic: crossover and mutation. They emulate the process of gene inheritance to create new solutions. Evolution: selection. It emulates Darwinian evolution to create a population from one generation to another.\n",
    "        Crossover: operates on 2 chromosomes, generating two offspring by combining characteristics. The performance of the algorithm highly depends on this operation.\n",
    "            Crossover rate (p c ): the number of offspring produced each generation divided by the population size.\n",
    "        Mutation: operates on 1 chromosome, producing random spontaneous changes in a gene, contributing to exploration of the search space.\n",
    "            Mutation rate (pm ): percentage of the total number of genes in the population to mutate. It controls the rate at which new genes are introduced into the population.\n",
    "        Selection: the selective pressure is critical for the algorithm.\n",
    "            High pressure: the search may end prematurely (intensification).\n",
    "            Low pressure: progress is slower than necessary (diversification).\n",
    "        The ideal approach is to maintain low pressure at the beginning for broad exploration, and high pressure towards the end to exploit more promising areas\n",
    "5.6.2.2.General structure:\n",
    "    Chromosome commonly represented as strings of bits or binary representation.\n",
    "    Parameters include population size and probability of applying the genetic operators\n",
    "5.6.2.3.New generation size: Uniform\n",
    "    New generation size = Same as previous generation\n",
    "    All offspring and some parents. Originally, all offspring replaced all parents\n",
    "5.6.2.4.New generation size: Expanded\n",
    "    New generation size = Previous generation size + number of offspring\n",
    "    All offspring and parents\n",
    "5.6.2.5.\n",
    "    Stochastic sampling: prevent super chromosomes. For instance, roulette wheel.\n",
    "    Deterministic sampling: sort chromosomes according to their fitness and choose the best ones. Elitist selection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675caf05",
   "metadata": {},
   "source": [
    "# Week7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ca7732",
   "metadata": {},
   "source": [
    "7.Computer vision\n",
    "7.1.Image Processing å›¾åƒå¤„ç†\n",
    "    A computer sees digital images as a matrix, where each cell represents a pixel.\n",
    "    Each pixel (or cell) has a value that indicates the intensity or color of that pixel\n",
    "    Aims to enhance relevant information in the image.\n",
    "    Usually is used to prepare images for further analysis and interpretation.\n",
    "    Image represented as n x m array I(x,y) â†’ image intensity array.\n",
    "    Cells are called pixels. Each number represent light intensity.\n",
    "    We will discuss two important techniques: histogram equalization, noise removal, and\n",
    "edge detection.\n",
    "\n",
    "7.1.1.Histogram Equalization ç›´æ–¹å›¾å‡è¡¡åŒ–\n",
    "    A (grayscale) image is a 2D function. In the provided example, we have 450 * 700 pixels, and each pixel can have a value between [0, 1] (or [0, 255] if we are using 8-bit presentation)\n",
    "    An image histogram is a plot of the gray-level frequencies (i.e., the number of pixels in the image that have that gray level).\n",
    "    To represent the histogram as probabilities ç›´æ–¹å›¾è¡¨ç¤ºä¸ºæ¦‚ç‡ (i.e., a normalized histogram), divide the frequency of each gray level by the total number of pixels.\n",
    "    L is the total number of gray levels (typically 256), ni is the number of pixels with value i, and n is the total number of pixels\n",
    "    In histogram equalization, the main idea is to redistribute é‡æ–°åˆ†é… the gray-level values uniformly.\n",
    "    7.1.1.1.Cumulative Distribution Function (CDF) ç´¯ç§¯åˆ†å¸ƒå‡½æ•°\n",
    "\n",
    "7.1.2.Image Processing: Noise Removal å›¾åƒå¤„ç†ï¼šå™ªå£°æ¶ˆé™¤\n",
    "    Real images always contain noise.\n",
    "    Smoothing å¹³æ»‘å¤„ç† is a process used to reduce noise and sharp transitions in an image.\n",
    "    Smoothing tries to remove isolated bright and dark regions.\n",
    "    Smoothing filters work by making a pixel's intensity closer to the average or median intensity of its surroundings, suppressing isolated extreme values.\n",
    "    Averaging + sliding â†’ convolution.\n",
    "    Has side-effect of blurring image.\n",
    "\n",
    "7.1.3.Image Processing: Averaging å›¾åƒå¤„ç†ï¼šå¹³å‡\n",
    "    Replace middle value in each window by average of all the values in the window.\n",
    "\n",
    "7.1.4.Image Processing: Edge Detection å›¾åƒå¤„ç†ï¼šè¾¹ç¼˜æ£€æµ‹\n",
    "    7.1.4.1.The Laplacian filter æ‹‰æ™®æ‹‰æ–¯æ»¤æ³¢å™¨:a spatial filter primarily used for edge detection.\n",
    "        It computes the second derivatives of an image, highlighting regions where there ar sudden changes in pixel intensity, which typically correspond to edges.\n",
    "        If the pixel is part of a flat region, the result is close to zero.\n",
    "    7.1.4.2.Canny edge detector è¾¹ç¼˜æ£€æµ‹å™¨ is an edge detection operator and can be broken down to different steps:\n",
    "        1. Apply Gaussian filter é«˜æ–¯æ»¤æ³¢å™¨ to smooth the image in order to remove the noise\n",
    "        2. Find the intensity gradients of the image and direction of each pixel.\n",
    "        3. Apply gradient magnitude thresholding æ¢¯åº¦å¹…åº¦é˜ˆå€¼ and suppress edges that are not the strongest.\n",
    "        4. Apply double threshold to determine which edges are strong, weak, or non-edges å¼ºè¾¹ç¼˜ã€å¼±è¾¹ç¼˜æˆ–éè¾¹ç¼˜.\n",
    "    7.1.4.3.Gaussian filter: reduces noise and detail in an image.\n",
    "        Instead of averaging all pixels equally (as in a mean filter), the Gaussian filter gives more weight to pixels near the center of the window å¯¹é è¿‘çª—å£ä¸­å¿ƒçš„åƒç´ èµ‹äºˆè¾ƒå¤§çš„æƒé‡ and less to those farther away è¾ƒè¿œçš„åƒç´ èµ‹äºˆè¾ƒå°çš„æƒé‡.\n",
    "    Gx : Gradient in the x-direction (vertical edges)\n",
    "    Gy : Gradient in the y-direction (horizontal edges)\n",
    "        Edges in an image are places where intensity changes rapidly å¼ºåº¦å¿«é€Ÿå˜åŒ– â€” that means high derivatives é«˜å¯¼æ•°.\n",
    "        Horizontal edges æ°´å¹³è¾¹ç¼˜: Large values in Gy\n",
    "        Vertical edges å‚ç›´è¾¹ç¼˜: Large values in Gx\n",
    "        Then we compute the magnitude and direction of the gradient æ¢¯åº¦çš„å¤§å°å’Œæ–¹å‘ at each pixel\n",
    "    Two thresholds are called minVal and maxVal.\n",
    "    Any edges with intensity gradient more than maxVal are sure to be edges\n",
    "    Those below minVal are sure to be non-edges, so discarded.\n",
    "    Those who lie between these two thresholds if they are connected to \"sure-edge\" pixels, they are considered to be part of edges\n",
    "\n",
    "7.2.Computer Vision è®¡ç®—æœºè§†è§‰\n",
    "7.2.1.Convolutional Neural Networks å·ç§¯ç¥ç»ç½‘ç»œ\n",
    "    Convolutions + Neural Networks = Convolutional Neural Networks (CNNs)\n",
    "    Convolutional neural networks (CNNs) is a class of artificial neural networks dominant in various computer vision tasks.\n",
    "    Convolutional neural network is composed of multiple building blocks, such as convolution layers, pooling layers, and fully connected layers, and is designed to automatically and adaptively learn spatial hierarchies of features\n",
    "    CNNs will try to learn low-level æ—©æœŸå±‚ features such as edges and lines in early layers, then parts of objects and then high-level representation of an object in subsequent layers.\n",
    "    CNNs can be interpreted as gradually transforming the images into a representation in which the classes are separable by a linear classifier.\n",
    "    CNNs are used for image recognition, object detection, and classification tasks.\n",
    "    CNNs excel at feature extraction, learning complex and abstract features from input data.\n",
    "    Parameter sharing å‚æ•°å…±äº« in CNNs reduces computational and memory requirements, which makes them efficient.\n",
    "    Convolution is a mathematical operator.\n",
    "        Continuous convolution è¿ç»­å·ç§¯\n",
    "        Discrete convolution ç¦»æ•£å·ç§¯\n",
    "        Two-dimensional convolution äºŒç»´å·ç§¯\n",
    "    Key Components:\n",
    "        1. Convolutional Layers å·ç§¯å±‚ â€“ Apply filters (kernels) to detect features such as edges, textures, and patterns.\n",
    "            Convolution is a mathematical operation which produces a filtered version of the original image.\n",
    "            This operation is called convolution because it involves â€œslidingâ€ the filter over the image, element-wise\n",
    "multiplying the values of the filter, and summing the results.\n",
    "            This process is repeated for every pixel in the image\n",
    "        2. Pooling Layers æ± åŒ–å±‚ â€“ Reduce spatial dimensions while retaining important features.\n",
    "            Pooling is a down-sampling ä¸‹é‡‡æ · operation that reduces the dimensionality of the feature map.\n",
    "            The pooling layer uses various filters to identify different parts of the image like edges, corners, body, feathers, eyes, and beak.\n",
    "        padding å¡«å……:\n",
    "            Sometimes, we expand the size of the input (or the previous layer) but treat the newly added units as having a fixed value (typically, zero) in order to save the information in the edges ä¿å­˜è¾¹ç¼˜ä¸­çš„ä¿¡æ¯\n",
    "        Stride æ­¥é•¿: refers to the step size by which a convolutional filter moves across an input image.\n",
    "            A stride of 1 means the filter moves one pixel at a time, leading to a highly detailed feature map with minimal size reduction.\n",
    "            A stride of 2 means the filter moves two pixels at a time, reducing the spatial dimension more aggressively.\n",
    "            Larger stride values result in smaller output feature maps and reduce computational cost, but may lose fine-grained details\n",
    "        3. Flattening layer æ‰å¹³åŒ–å±‚ â€“ convert feature maps into a one-dimensional vector\n",
    "            After the convolution and pooling operations, the feature maps still exist in a multi-dimensional format.\n",
    "            Flattening converts these feature maps into a one-dimensional vector. It prepares the data to be passed into fully connected layers for classification or regression tasks.\n",
    "            For an RGB image, there are typically separate kernels for each colour channel because different features might be more visible or relevant in one channel compared to the others.\n",
    "            Each filter produces a separate feature map.\n",
    "            The output normally has multiple channels, where each channel is a feature map corresponding to a particular kernel\n",
    "        4. Fully Connected Layers å…¨è¿æ¥å±‚ â€“ Connect extracted features to output layers for classification or regression.\n",
    "        5. Output layer è¾“å‡ºå±‚ â€“ choose between classes\n",
    "\n",
    "7.2.2.VGG16\n",
    "    It is a 16-layer deep model, consisting of 13 convolutional layers, 3 fully connected layers, and 5 pooling layers.\n",
    "    The architecture is characterized by the use of small 3x3 convolution kernels and ReLU activation functions\n",
    "\n",
    "7.2.3.AlexNet\n",
    "    AlexNet is a CNN architecture developed for image classification task\n",
    "    It has 8 layers (5 conv + 3 fully connected) and has been trained through GPU parallelization.\n",
    "\n",
    "7.3.Cognitive Vision è®¤çŸ¥è§†è§‰\n",
    "7.3.1.principles åŸåˆ™\n",
    "    In many AI systems, perception is treated as a black box that just turns raw imagesbinto labels.\n",
    "    The system uses mostly static data (like images or single video frames) and doesnâ€™t really \"understand\" .\n",
    "    Moving from raw pixel data to high-level symbolic understanding é«˜çº§ç¬¦å·ç†è§£ is not easy.\n",
    "    Thereâ€™s often no causal link â€”system doesnâ€™t understand why things happen ä¸ç†è§£äº‹æƒ…å‘ç”Ÿçš„åŸå› , or how the present relates to the past.\n",
    "    Because of this, such systems struggle to anticipate the future å¾ˆéš¾é¢„æµ‹æœªæ¥.\n",
    "\n",
    "7.3.2.Vision and Reasoning Interaction è§†è§‰ä¸æ¨ç†äº¤äº’\n",
    "    Cognitive vision instead of just extracting features (like edges or shapes), it aims to understand and reason ç†è§£å’Œæ¨ç† about whatâ€™s happening in the scene\n",
    "    The system predicts é¢„æµ‹ what it expects to see or sense.\n",
    "    Then it explores æ¢ç´¢ to check if its predictions are correct.\n",
    "    This predictionâ€“exploration loop é¢„æµ‹-æ¢ç´¢å¾ªç¯ helps the system go from just labeling things to truly interacting with and learning about the world, like humans do.\n",
    "    So, cognitive vision è®¤çŸ¥è§†è§‰ is about combining perception with reasoning, learning, and action æ„ŸçŸ¥ä¸æ¨ç†ã€å­¦ä¹ å’Œè¡ŒåŠ¨, enabling systems to adapt, anticipate the future, and deal with uncertainty.\n",
    "    Cognitive vision to support human-robot interaction.\n",
    "    iCubâ€™s behavior driven only by the direction of the subjectâ€™s gaze making explicit intention to reach for the left or right hand.\n",
    "    Cognitive Vision: Vision and Reasoning Interaction\n",
    "    Cognitive vision can be used for signature of biological motion.\n",
    "    Angular velocity and curvature of the trajectory are features that CV systems might analyze to identify biological motions.\n",
    "    Hand during drawing or writing.\n",
    "    Knee or ankle during walking.\n",
    "    Visually measured independently of its shape and color.\n",
    "    Cognitive Vision is not just about identifying \"what æ˜¯ä»€ä¹ˆ\" is in the scene and \"where åœ¨å“ªé‡Œ\" it is.\n",
    "    Most current vision systems treat perception as a standalone taskâ€”ç‹¬ç«‹çš„ä»»åŠ¡ just detect and classify. Cognitive vision challenges æŒ‘æˆ˜ this narrow view.\n",
    "    Cognitive vision combines V and R to drive action ç»“åˆè§†è§‰å’Œæ„ŸçŸ¥æ¥é©±åŠ¨è¡ŒåŠ¨. It's a multi-modal systemå¤šæ¨¡æ€ç³»ç»Ÿ â€”vision works together with other senses and cognitive functions.\n",
    "    Questions beyond what, where â†’ why, how, who.\n",
    "    Also how synthesize visual information to anticipate action effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30c8bdd",
   "metadata": {},
   "source": [
    "# Week 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4983cf",
   "metadata": {},
   "source": [
    "8.Knowledge Representation and Uncertain Reasoning çŸ¥è¯†è¡¨ç¤ºä¸ä¸ç¡®å®šæ€§æ¨ç†\n",
    "8.1.Knowledge representation çŸ¥è¯†è¡¨ç¤º\n",
    "    Levels of Abstraction æŠ½è±¡å±‚æ¬¡\n",
    "    Iconic Representations æ ‡å¿—æ€§è¡¨ç°\n",
    "    Symbolic Representations ç¬¦å·è¡¨å¾\n",
    "    Rule-Based Systems åŸºäºè§„åˆ™çš„ç³»ç»Ÿ\n",
    "        A production rule äº§ç”Ÿå¼è§„åˆ™ has the form\n",
    "    8.1.5.Inference Networks æ¨ç†ç½‘ç»œ\n",
    "        The interdependencies among rules, such as r1_1 and r1_2 define a network ä¸€ä¸ªç½‘ç»œ\n",
    "        Inference network æ¨ç†ç½‘ç»œ shows which facts can be logically combined to form new facts or conclusions\n",
    "        The facts can be combined using â€œandâ€, â€œorâ€ and â€œnotâ€ â€œå’Œâ€ã€â€œæˆ–â€å’Œâ€œéâ€\n",
    "        e.g: Professional contentment is true if either job satisfaction or large salary is true (or both are true).\n",
    "    8.1.6.Deduction, Abduction and Induction æ¼”ç»æ¨ç†ã€æº¯å› æ¨ç†å’Œå½’çº³æ¨ç†\n",
    "        Deduction - Rules that make up inference network can be used to link cause and effect:\n",
    "            if <cause> then <effect>\n",
    "        Abduction - Many problems, such as diagnosis, involve reasoning in reverse, i.e, find a cause, given an effect.\n",
    "            å·²çŸ¥ç»“æœï¼Œæ‰¾å‡ºåŸå› \n",
    "        Induction - If we have many examples of cause and effect, infer the rule è§„å¾‹ that links them\n",
    "            e.g:rule r1_1\n",
    "                if the employer of Person is acme\n",
    "                then the salary of Person becomes large.\n",
    "            Inferring a rule from a set of examples of cause and effect is induction å½’çº³æ³•\n",
    "    Closed-World Assumption å°é—­ä¸–ç•Œå‡è®¾\n",
    "    8.1.8.Ontologies and Ontology Engineering æœ¬ä½“è®ºä¸æœ¬ä½“å·¥ç¨‹\n",
    "        An ontology æœ¬ä½“è®º organises everything into a hierarchy of cat\n",
    "    8.1.9.Categories and Objects ç±»åˆ«å’Œå¯¹è±¡\n",
    "        much reasoning takes place at level of categories å¾ˆå¤šæ¨ç†å‘ç”Ÿåœ¨ç±»åˆ«å±‚é¢\n",
    "        Categories ç±»åˆ« organise and simplify knowledge base through inheritance ç»§æ‰¿.\n",
    "            if all instances of category Food are edible, and\n",
    "            if Fruit is a subclass of Food and Apples is a subclass of Fruit,\n",
    "            then infer that every apple is edible.\n",
    "        Individual apples inherit ç»§æ‰¿ property of edibility\n",
    "        in this case, from membership in the Food category.\n",
    "        Subclass relations organise categories into a taxonomy, or taxonomic hierarch åˆ†ç±»ä½“ç³»ï¼Œæˆ–ç§°åˆ†ç±»å­¦ä½“ç³»\n",
    "\n",
    "8.2.Reasoning æ¨ç†\n",
    "    Knowledge Bases çŸ¥è¯†åº“\n",
    "    Natural languages are ambiguous æ­§ä¹‰æ€§\n",
    "    8.2.3.Reasoning system for categories ç±»åˆ«æ¨ç†ç³»ç»Ÿ\n",
    "        Two closely related families of systems:\n",
    "        â€¢ semantic networks è¯­ä¹‰ç½‘ç»œ:\n",
    "            â€¢ graphical aids for visualizing a knowledge base\n",
    "            â€¢ efficient algorithms for inferring properties of object based in category membership\n",
    "        â€¢ description logics æè¿°é€»è¾‘:\n",
    "            â€¢ formal language for constructing and combining category definitions\n",
    "            â€¢ efficient algorithms for deciding subset and superset relationship\n",
    "    8.2.4.Semantic Networks è¯­ä¹‰ç½‘ç»œ\n",
    "        Attributes and relationships can be represented as a network, known as an associative network or semantic network å…³è”ç½‘ç»œæˆ–è¯­ä¹‰ç½‘ç»œ\n",
    "    Classes and Instances ç±»å’Œå®ä¾‹\n",
    "    8.2.6.Propositional Logic å‘½é¢˜é€»è¾‘\n",
    "        Reasoning is independent of definitions of propositions æ¨ç†ç‹¬ç«‹äºå‘½é¢˜çš„å®šä¹‰\n",
    "        Combine into more complex sentences using operators not, and, or, implies, iff éã€ä¸ã€æˆ–ã€è•´æ¶µã€å½“ä¸”ä»…å½“\n",
    "        Propositional connectives è¿æ¥è¯\n",
    "    8.2.7.First-Order Logic ä¸€é˜¶é€»è¾‘\n",
    "        First-Order Logic ä¸€é˜¶é€»è¾‘ can express knowledge about objects, properties and relationships between objects\n",
    "        e.g. âˆ€x likes(x, a), âˆƒx likes(x, mother_of (y))\n",
    "            Second occurrences of x are bound é™å®š by quantifier (âˆ€ in first case, âˆƒ in second) and y in the second formula is free è‡ªç”±\n",
    "\n",
    "8.3.Uncertainty ä¸ç¡®å®š\n",
    "    But how can uncertainty ä¸ç¡®å®šæ€§ be handled?\n",
    "    Uncertainty may arise from:\n",
    "        Confidence factors: Uncertain evidence (Not certain that Joe Bloggs works for ACME.)\n",
    "        Bayesian inference: Uncertain link between evidence and conclusion. (Cannot be certain that ACME employee earns a large salary, just likely.)\n",
    "        Fuzzy Logic: Vague rule. (What is a â€œlargeâ€?)\n",
    "    8.3.1.Confidence Factors\n",
    "        Uncertainty in antecedents å‰ä»¶çš„ä¸ç¡®å®šæ€§: based on user information and deduced from another rule.\n",
    "        Uncertainty in a rule è§„åˆ™çš„ä¸ç¡®å®šæ€§: based on expertâ€™s rule confidence and propagated to the conclusion.\n",
    "        Reasoning with confident factors åŸºäºç½®ä¿¡å› ç´ çš„æ¨ç†: two independent pieces of evidence should increase confidence. Then the rule is inverted\n",
    "        Inference network æ¨ç†ç½‘ç»œ: sequence of relationships between facts and confidence factors\n",
    "\n",
    "8.4.Bayesian inference è´å¶æ–¯æ¨æ–­\n",
    "    8.4.1.Probabilistic Inference æ¦‚ç‡æ¨ç†\n",
    "        Axioms å…¬ç†:\n",
    "            â€¢ 0 â‰¤ P(A=a) â‰¤ 1\n",
    "            â€¢ P(True) = 1, P(False) = 0\n",
    "            â€¢ P(A v B) = P(A) + P(B) - P(A ^ B)\n",
    "        Properties ç‰¹æ€§:\n",
    "            â€¢ P(~A) = 1 - P(A)\n",
    "            â€¢ P(A) = P(A ^ B) + P(A ^ ~B)\n",
    "            â€¢ Sum{P(A=a)} = 1, where the sum is over all possible values a in the sample space of A\n",
    "    Joint Probability Distribution è”åˆæ¦‚ç‡åˆ†å¸ƒ\n",
    "    Conditional Probability æ¡ä»¶æ¦‚ç‡\n",
    "        P(A | B) = P(A, B) / P(B)\n",
    "    8.4.4.Bayesâ€™ Rule è´å¶æ–¯è§„åˆ™\n",
    "        P(A | B) = P(B | A) P(A) / P(B)\n",
    "    8.4.5.Belief Networks ä¿¡å¿µç½‘ç»œ\n",
    "        Topology æ‹“æ‰‘ç»“æ„: Three connection types\n",
    "\n",
    "8.5.Fuzzy logic æ¨¡ç³Šé€»è¾‘\n",
    "    8.5.1.Ambiguity æ­§ä¹‰\n",
    "        Ambiguity is related to the degree ç¨‹åº¦ to which events occur regardless of the probability of their occurrence.\n",
    "        For example, the degree of youth in a person  is a fuzzy æ¨¡ç³Š event regardless of being a random variable.\n",
    "    8.5.2.Fuzzy Sets æ¨¡ç³Šé›†\n",
    "        Fuzzy Sets: Support æ¨¡ç³Šé›†ï¼šæ”¯æŒ\n",
    "        Fuzzy Sets: Crossover Point æ¨¡ç³Šé›†ï¼šäº¤å‰ç‚¹: 0.5\n",
    "        Fuzzy Sets: Core æ¨¡ç³Šé›†ï¼šæ ¸å¿ƒ: 1\n",
    "        Fuzzy Sets: Height æ¨¡ç³Šé›†ï¼šé«˜åº¦\n",
    "        Fuzzy Sets: Centre Value æ¨¡ç³Šé›†ï¼šä¸­å¿ƒå€¼ \n",
    "        Fuzzy Sets: Î±-cut æ¨¡ç³Šé›†ï¼šÎ±-æˆªé›†\n",
    "            Properties. Given a fuzzy set A defined in X and two values Î±1 and Î±2 âˆˆ [0; 1] such that Î±1 > Î±2\n",
    "    8.5.3.Membership functions æˆå‘˜å‡½æ•°\n",
    "        Membership functions: Triangular  éš¶å±å‡½æ•°ï¼šä¸‰è§’å‡½æ•°\n",
    "        Membership functions: Trapezoidal éš¶å±å‡½æ•°ï¼šæ¢¯å½¢\n",
    "        Membership functions: Gaussian éš¶å±å‡½æ•°ï¼šé«˜æ–¯å‡½æ•°\n",
    "        Membership functions: Bell-shaped æˆå‘˜å‡½æ•°ï¼šé’Ÿå½¢\n",
    "        Membership functions: Sigmoid\n",
    "    Rules è§„åˆ™\n",
    "    Defuzzification å»æ¨¡ç³ŠåŒ–\n",
    "    Fuzzy Inference æ¨¡ç³Šæ¨ç†"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
