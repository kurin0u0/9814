{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12c95b42",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf854ab0",
   "metadata": {},
   "source": [
    "1.1.Agent\n",
    "    Reactive Agentååº”ï¼šåŸºäºå½“å‰æ„ŸçŸ¥è¡ŒåŠ¨ï¼Œè·¯å¾„å¯èƒ½æ¬¡ä¼˜. \n",
    "    Model-based AgentåŸºäºæ¨¡å‹ï¼šè·Ÿè¸ªçœ‹ä¸åˆ°äº‹ç‰©æ¥å¤„ç†éƒ¨åˆ†å¯è§‚æµ‹æ€§ï¼Œä½†ä¸èƒ½è®¡åˆ’æœªæ¥ï¼Œå®ç°ä¾‹å¦‚è‡ªåŠ¨é©¾é©¶/æ‰«åœ°æœºå™¨äºº. \n",
    "    Planning Agentè§„åˆ’ï¼šä¸æ¡ä»¶è¡ŒåŠ¨ä¸åŒï¼Œæœ‰æœªæ¥åæœè€ƒè™‘ï¼Œéœ€è¦æœç´¢ï¼Œçµæ´»æ˜“å˜ä½†ååº”æ…¢. \n",
    "        ä¾‹å¦‚ï¼šGoal-based AgentåŸºäºç›®æ ‡ï¼šåœ°å›¾æœç´¢ï¼Œè±¡æ£‹. \n",
    "    Learning Agentå­¦ä¹ ï¼šåŒ…å«performance element:è¯»sensorsæ¥è¡ŒåŠ¨/critic:ç»™åé¦ˆ/Learning element:ç”¨â‘¡ç¡®å®šä¿®æ”¹â‘ /problem generator:è®¾æ–°ä»»åŠ¡ï¼Œç»™ä¿¡æ¯ã€‚ä¼—æ¨¡å—éå­¤ç«‹. \n",
    "  \n",
    "1.2.Searchï¼šç­–ç•¥ä¸åŒåœ¨äºæ‰©å¤§è¾¹ç•Œæ–¹å¼. \n",
    "\n",
    "1.2.1.uninformedï¼š  \n",
    "    BFSå¹¿åº¦ï¼š  \n",
    "    DFSæ·±åº¦ï¼šå †æ ˆï¼ˆé™¤iddfså¤–å…¶ä»–éƒ½é˜Ÿåˆ—ï¼‰. \n",
    "    IDDFSè¿­ä»£æ·±åŒ–æ·±åº¦ï¼šä¸è¶…ç»™å®šæ·±åº¦è¿­ä»£dfs. \n",
    "    UCSç»Ÿä¸€æˆæœ¬ï¼šé€‰pathå¼§çš„å’Œæœ€å°‘ï¼Œæˆæœ¬ç›¸åŒå˜bfs. \n",
    "\n",
    "1.2.2.informedçŸ¥æƒ…æœç´¢ï¼šå¯å‘å¼ï¼Œç”¨domain knowledgeï¼Œæœæœ€ä½³çŒœæµ‹ç›®æ ‡è¡Œ. \n",
    "    GBFSè´ªå©ªï¼šé€‰æœ€ä½heuristic cost. \n",
    "    A*:ç»Ÿä¸€æˆæœ¬+è´ªå©ª  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c188ec0",
   "metadata": {},
   "source": [
    "# Week 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcf276",
   "metadata": {},
   "source": [
    "2.1.Supervised Learning ç›‘ç£å­¦ä¹ \n",
    "    An equation relating input to output\n",
    "    Search through family of possible equations to find one that fits training data well\n",
    "\n",
    "2.1.1.Regressionå›å½’\n",
    "    å•å˜é‡å›å½’é—®é¢˜ï¼ˆä¸€ä¸ªè¾“å‡ºï¼Œå®æ•°å€¼ï¼‰\n",
    "\n",
    "2.1.2.Binary Classification äºŒå…ƒåˆ†ç±»\n",
    "    äºŒå…ƒåˆ†ç±»é—®é¢˜ï¼ˆä¸¤ä¸ªç¦»æ•£ç±»åˆ«ï¼‰\n",
    "\n",
    "2.1.3.Multiclass Classification\n",
    "    å¤šç±»åˆ†ç±»é—®é¢˜ï¼ˆç¦»æ•£ç±»åˆ«ï¼Œ>2 ä¸ªå¯èƒ½çš„å€¼ï¼‰\n",
    "\n",
    "2.2.Unsupervised Learning æ— ç›‘ç£å­¦ä¹ \n",
    "    å­¦ä¹ æ— æ ‡ç­¾æ•°æ®é›†\n",
    "    Clustering èšç±»ï¼šå°†ç›¸ä¼¼çš„æ•°æ®ç‚¹åˆ†ç»„åœ¨ä¸€èµ·\n",
    "\n",
    "2.3.Reinforcement Learning å¼ºåŒ–å­¦ä¹ \n",
    "    ä¸€ç»„ States çŠ¶æ€/ Actions åŠ¨ä½œ/ Rewards å¥–åŠ±\n",
    "    Goal: take actions to change the state so that you receive rewards\n",
    "    You have to explore the environment yourself to gather data as you go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001099e9",
   "metadata": {},
   "source": [
    "2.4.Decision Trees å†³ç­–æ ‘ï¼ˆsupervised machine learningï¼‰\n",
    "    åº”ç”¨: classification and regression\n",
    "    partition the data into subsets that are increasingly homogeneousåŒè´¨ with respect to the response variable\n",
    "    Feature A may be the most important feature(å®ƒå°†è®­ç»ƒæ ·æœ¬åˆ’åˆ†ä¸ºæ›´æ¥è¿‘å®Œå…¨æ­£é¢æˆ–å®Œå…¨è´Ÿé¢çš„å­é›†ï¼ˆå³æ›´åŒè´¨åŒ–ï¼‰)ï¼Œso check it earlier(å€’ç€ç”»)\n",
    "    Goal:generalizesæ³›åŒ– well from the training data and accurately classifies previously unseen sampleså‡†ç¡®åˆ†ç±»å…ˆå‰æœªè§è¿‡çš„æ ·æœ¬\n",
    "\n",
    "2.4.1.Entropy ç†µ (randomness or uncertainty éšæœºæ€§æˆ–ä¸ç¡®å®šæ€§)\n",
    "    ğ»(âŸ¨p1,Â· Â· Â· , pn âŸ©) = sigma(i=1,n) âˆ’pğ‘–log2ğ‘ğ‘–\n",
    "    maximized when all outcomes are equally likely\n",
    "    minimized when the probability distribution is highly concentrated around a single outcome\n",
    "    å†³ç­–æ ‘é€šè¿‡åœ¨æ¯ä¸ªæ­¥éª¤ä¸­é€‰æ‹©ã€æœ€å°ã€‘ç†µçš„ç‰¹å¾æ¥æ„å»º\n",
    "\n",
    "2.4.2.Minimal Error Pruning æœ€å°é”™è¯¯å‰ªæ\n",
    "    prune branches that do not provide much benefit in classifying the items (aids generalization, avoids overfitting)\n",
    "    Laplace error æ‹‰æ™®æ‹‰æ–¯è¯¯å·®:E= 1âˆ’(n+1)/(N+k)\n",
    "        N = total number of (training) items at the node\n",
    "        n = number of (training) items in the majority class\n",
    "        k = number of classes\n",
    "    å¦‚æœå­èŠ‚ç‚¹çš„å¹³å‡æ‹‰æ™®æ‹‰æ–¯è¯¯å·®è¶…è¿‡çˆ¶èŠ‚ç‚¹ï¼Œåˆ™å‰ªé™¤å­èŠ‚ç‚¹\n",
    "\n",
    "2.4.3.Tree Limitations\n",
    "    high varianceé«˜æ–¹å·®(ä¸ç¨³å®š): 1.arise from a tiny change in the training data, leading to completely different predictions\n",
    "                               2.æ¨¡å‹å€¾å‘äºâ€œè®°å¿†â€è®­ç»ƒæ•°æ®ï¼ˆoverfitting è¿‡æ‹Ÿåˆï¼‰ï¼Œè€Œä¸æ˜¯å­¦ä¹ æ½œåœ¨çš„æ¨¡å¼\n",
    "                               3.ä½æ–¹å·®: æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šæ›´åŠ ç¨³å®šå’Œä¸€è‡´\n",
    "    Suboptimal predictive performance é¢„æµ‹æ€§èƒ½ä¸ä½³: Single trees often fail to achieve strong generalization æ³›åŒ–èƒ½åŠ›\n",
    "    generalization æ³›åŒ– æ˜¯æŒ‡æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨æœªè§è¿‡æ•°æ®ä¸Šè¡¨ç°è‰¯å¥½ï¼Œè€Œä¸ä»…ä»…æ˜¯è®­ç»ƒæ•°æ®\n",
    "    divided into three subsets: training, validation,and test\n",
    "                              1.è®­ç»ƒé›†ï¼šç”¨äºè®­ç»ƒå†³ç­–æ ‘æ¨¡å‹ã€‚\n",
    "                              2.éªŒè¯é›†ï¼šç”¨äºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è¯„ä¼°ä¸åŒçš„é…ç½®ï¼ˆè¶…å‚æ•°ï¼‰\n",
    "                              3.æµ‹è¯•é›†ï¼šä¸ºæœ€ç»ˆå†³ç­–æ ‘æ¨¡å‹åœ¨æœªè§è¿‡æ•°æ®ä¸Šæä¾›æ— åè¯„ä¼°ã€‚\n",
    "    Bias åå·®: systematic error ç³»ç»Ÿæ€§è¯¯å·®, ç”¨ç®€å•çš„æ¨¡å‹è¿‘ä¼¼ç°å®é—®é¢˜æ—¶å¼•å…¥çš„\n",
    "        A high bias model makes strong assumptions about the data, leading to underfittingæ¬ æ‹Ÿåˆ\n",
    "    bias-variance tradeoff:å¤æ‚çš„æ¨¡å‹å¯ä»¥å¸®åŠ©æˆ‘ä»¬é¿å…åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰ï¼Œè€Œé™åˆ¶æ¨¡å‹å¤æ‚åº¦å¯ä»¥å¸®åŠ©æˆ‘ä»¬é¿å…è¿‡æ‹Ÿåˆï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "\n",
    "2.4.4.Tree Depth\n",
    "    Shallow trees æµ…æ ‘ç”±äºæ ‘æ²¡æœ‰è¶³å¤Ÿçš„èŠ‚ç‚¹æ¥æ•æ‰æ•°æ®çš„å¤æ‚æ€§ï¼Œå› æ­¤ä¼šé­å—é«˜åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰\n",
    "    Deep trees æ·±æ ‘å®¹æ˜“å—åˆ°é«˜æ–¹å·®ï¼ˆè¿‡æ‹Ÿåˆï¼‰çš„å½±å“ï¼Œå› ä¸ºæ ‘å¯èƒ½ä¼šä¸ºæ¯ä¸ªæ•°æ®æ ·æœ¬åˆ†é…ä¸€ä¸ªç‹¬ç‰¹çš„è·¯å¾„ï¼Œè€Œä¸æ˜¯å­¦ä¹ ä¸€èˆ¬æ¨¡å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad0483",
   "metadata": {},
   "source": [
    "2.5.Ensemble Learning with Trees åŸºäºæ ‘çš„é›†æˆå­¦ä¹ \n",
    "2.5.1.Bagged Tree è£…è¢‹æ ‘\n",
    "    relies on bootstrapping è‡ªåŠ©é‡‡æ · to create multiple training datasets\n",
    "    bootstrapping: with replacement æœ‰æ”¾å›, sample is the same size è§„æ¨¡ç›¸åŒ as the original dataset\n",
    "        37% out-of-bag (OOB) samples: æœªåŒ…å«åœ¨è‡ªåŠ©é‡‡æ ·ä¸­çš„æ•°æ®ç‚¹\n",
    "    é›†æˆä¸­çš„æ¯ä¸ªæ¨¡å‹éƒ½ä¼šä¸ºæ–°æ ·æœ¬ç”Ÿæˆä¸€ä¸ªé¢„æµ‹ï¼Œæœ€ç»ˆé¢„æµ‹æ˜¯é€šè¿‡the majority vote ruleå¤šæ•°æŠ•ç¥¨è§„åˆ™ï¼ˆç”¨äºåˆ†ç±»ï¼‰æˆ–é€šè¿‡å¹³å‡é¢„æµ‹å€¼ï¼ˆç”¨äºå›å½’ï¼‰æ¥åšå‡ºçš„\n",
    "    Advantages:1.reduces the variance\n",
    "               2.average prediction has lower variance\n",
    "               3.errors(vary in different directions) partially cancel out\n",
    "               4.No separate test set required\n",
    "               5.OOB samples provides an unbiased estimate of performance æ— åçš„æ€§èƒ½ä¼°è®¡\n",
    "    æ¯æ£µå­æ ‘æœ€ç»ˆéƒ½æ˜¯ç‹¬ä¸€æ— äºŒçš„,ç„¶è€Œï¼Œè¿™äº›æ ‘å½¼æ­¤ä¹‹é—´ä»ç„¶å­˜åœ¨ä¸€å®šçš„correlatedç›¸å…³æ€§,å› æ­¤ï¼Œè£…è¢‹æ–¹æ³•å®ç°çš„æ–¹å·®å‡å°‘å¯ä»¥è¿›ä¸€æ­¥æ”¹è¿›ï¼Œä»ç»Ÿè®¡å­¦çš„è§’åº¦æ¥çœ‹ï¼Œé€šè¿‡åœ¨æ ‘æ„å»ºè¿‡ç¨‹ä¸­å¼•å…¥additional randomnessé¢å¤–çš„éšæœºæ€§ï¼Œå¯ä»¥å‡å°‘é¢„æµ‹å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§\n",
    "\n",
    "2.5.2.Random Forest éšæœºæ£®æ—\n",
    "    æœ€ç»ˆé¢„æµ‹: the majority vote rule\n",
    "    åœ¨æ¯ä¸ªæ ‘çš„åˆ†å‰²ç‚¹ï¼Œç®—æ³•éšæœºé€‰æ‹© k predictors (features) k ä¸ªé¢„æµ‹å™¨ï¼ˆç‰¹å¾ï¼‰ã€‚k = âˆšpï¼Œå…¶ä¸­ p æ˜¯ç‰¹å¾çš„æ€»æ•°\n",
    "    ç„¶åï¼Œæ ‘ä»…ä»è¿™äº› k ä¸ªç‰¹å¾ä¸­é€‰æ‹©æœ€ä½³åˆ†å‰²\n",
    "    è¿™ç§éšæœºæ€§å‡å°‘äº†æ ‘ä¹‹é—´çš„ç›¸å…³æ€§ï¼ˆè¿™æ˜¯è£…è¢‹æ ‘çš„é—®é¢˜ï¼‰\n",
    "    ä¸è£…è¢‹æ³•ç›¸æ¯”ï¼Œéšæœºæ£®æ—åœ¨é€æ£µæ ‘çš„åŸºç¡€ä¸Šæ›´å…·æœ‰è®¡ç®—æ•ˆç‡ï¼Œå› ä¸ºæ ‘æ„å»ºè¿‡ç¨‹ä»…éœ€åœ¨æ¯ä¸ªåˆ†è£‚ç‚¹è¯„ä¼°a fraction of the original featuresåŸå§‹ç‰¹å¾çš„ä¸€éƒ¨åˆ†ï¼Œå°½ç®¡éšæœºæ£®æ—é€šå¸¸éœ€è¦more treesæ›´å¤šçš„æ ‘\n",
    "    é€‰æ‹©éšæœºæ£®æ—å’Œ Bagging ä¸­æ ‘çš„æ•°é‡ï¼ˆmï¼‰ï¼š1.Variance reduction æ–¹å·®å‡å°‘: å¢åŠ æ›´å¤šçš„æ ‘å¯ä»¥å‡å°‘æ–¹å·®ï¼Œä½¿é¢„æµ‹æ›´åŠ ç¨³å®š\n",
    "                                      2.Constraints çº¦æŸæ¡ä»¶: å½“å¢åŠ  m æ—¶ï¼Œè®­ç»ƒæ—¶é—´ã€å†…å­˜ä½¿ç”¨å’Œè¿‡æ‹Ÿåˆæ˜¯ä¸»è¦çš„é™åˆ¶å› ç´ \n",
    "                                      3.Test error behavior æµ‹è¯•è¯¯å·®è¡Œä¸º: æµ‹è¯•è¯¯å·®é€šå¸¸éšç€ m çš„å¢åŠ è€Œå•è°ƒé€’å‡â€”â€”èµ·åˆè¿…é€Ÿä¸‹é™ï¼Œç„¶åè¶‹äºå¹³ç¨³ï¼Œåœ¨è¶³å¤Ÿå¤šçš„æ ‘ä¹‹åå‡ ä¹ä¿æŒæ’å®š\n",
    "\n",
    "2.5.3.Boosting Trees(AdaBoost)æå‡æ ‘\n",
    "    æ¯æ¬¡è¿­ä»£ä¸­ï¼ŒAdaBoost æ ¹æ®å½“å‰çš„åŠ æƒæ•°æ®ç‚¹é€‰æ‹©æœ€ä½³åˆ†ç±»å™¨\n",
    "    åœ¨ k æ¬¡è¿­ä»£ä¸­è¢«é”™è¯¯åˆ†ç±»çš„æ•°æ®ç‚¹åœ¨(k+1)æ¬¡è¿­ä»£ä¸­è·å¾—higher weightsæ›´é«˜çš„æƒé‡\n",
    "    å› æ­¤ï¼Œéš¾ä»¥åˆ†ç±»çš„æ ·æœ¬ä¼šé€æ¸è·å¾—è¶Šæ¥è¶Šå¤§çš„æƒé‡\n",
    "    è¿™ä¸ªè¿‡ç¨‹ç¡®ä¿æ¯æ¬¡è¿­ä»£éƒ½ä¸“æ³¨äºå­¦ä¹ æ•°æ®çš„æŸä¸ªä¸åŒæ–¹é¢\n",
    "    æœ€åï¼Œè¿™äº›weighted classifiersåŠ æƒåˆ†ç±»å™¨çš„åºåˆ—è¢«ç»„åˆæˆä¸€ä¸ªé›†æˆï¼Œäº§ç”Ÿä¸€ä¸ªå¼ºå¤§çš„æ•´ä½“æ¨¡å‹\n",
    "    Algorithm:è®¡ç®—\n",
    "\n",
    "\n",
    "2.5.4.å¯¹æ¯”\n",
    "    è£…è¢‹æ³•é€šè¿‡åœ¨è‡ªåŠ©é‡‡æ ·ä¸Šè®­ç»ƒå¤šä¸ªæ ‘å¹¶èšåˆå®ƒä»¬çš„é¢„æµ‹æ¥é™ä½high varianceé«˜æ–¹å·®\n",
    "    éšæœºæ£®æ—é€šè¿‡åœ¨è®­ç»ƒä¸­æ·»åŠ randomnesséšæœºæ€§ï¼ˆä¾‹å¦‚ï¼Œåœ¨æ¯ä¸ªåˆ†è£‚æ—¶é€‰æ‹©éšæœºç‰¹å¾å­é›†ï¼‰è¿›ä¸€æ­¥variance reductionå‡å°‘æ–¹å·®.æ ‘æ˜¯in parallelå¹¶è¡Œä¸”åŒç­‰æƒé‡è®­ç»ƒçš„ï¼Œè¿™èƒ½æœ‰æ•ˆå‡å°‘æ–¹å·®ï¼Œä½†å¹¶ä¸èƒ½æ˜¾è‘—reduce biaså‡å°‘åå·®\n",
    "    æå‡æ–¹æ³•é€šè¿‡sequentiallyé¡ºåºè®­ç»ƒæ ‘æ¥å‡å°‘bias and varianceåå·®å’Œæ–¹å·®ï¼Œå…¶ä¸­æ¯æ£µæ–°æ ‘ä¸“æ³¨äºçº æ­£å‰ä¸€æ£µæ ‘çš„é”™è¯¯ï¼Œå¹¶æ ¹æ®å…¶æ€§èƒ½å¯¹æ ‘è¿›è¡ŒåŠ æƒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45199a53",
   "metadata": {},
   "source": [
    "# Week 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93278383",
   "metadata": {},
   "source": [
    "3.1.Artificial Neural Networksäººå·¥ç¥ç»ç½‘ç»œ\n",
    "    This model consists of many interconnected processing units (neurons)ç¥ç»å…ƒ that work in parallel to accomplish a global task\n",
    "    model relationships between inputs and outputs or to discover patterns in data\n",
    "    Learning occurs by adapting weights, architecture, and activation/transfer functions to improve performance\n",
    "    Characterized by: Number of neurons, Interconnection architecture, Weight values, Activation and transfer functions\n",
    "\n",
    "3.1.1.model of a neuron\n",
    "    An extra constant w0 called the biasåå·® is also added\n",
    "\n",
    "3.1.2.Neural Networks are made up of nodes which have:\n",
    "    Input edges, each with some weight\n",
    "    Output edges (with weights)\n",
    "    An activation level (a function of the inputs)\n",
    "        Weights can be positive or negative and may change overtime (learning).\n",
    "        The input function is the weighted sum of the activation levels of inputs.\n",
    "        The activation level is a non-linear transfer function (activation function), g, of this input.\n",
    "        z= g(s)= g(ğ‘¤0 + Ïƒğ‘– ğ‘¤ğ‘–ğ‘¥ğ‘–) å¿…é¡»å¤§äº0æ‰æ˜¯1\n",
    "\n",
    "3.2.Perceptronæ„ŸçŸ¥å™¨\n",
    "    An artificial neuron with step transfer functioné˜¶è·ƒä¼ é€’å‡½æ•°(é›¶ç‚¹å·¦å³0,1) is called a Perceptron\n",
    "    The bias (w0) was thought of as a kind of thresholdé˜ˆå€¼. If the combination -Ïƒğ‘– ğ‘¤ğ‘–ğ‘¥ğ‘– is less than this threshold, the neuron would \"fire\" (its output would be 1)\n",
    "    The higher the bias, the more likely the neuron is to fire\n",
    "    Later on, alternative transfer functions were introduced which are continuous and (mostly) differentiable\n",
    "3.2.1.hyperplane\n",
    "    The weights and bias of a Perceptron define a hyperplaneè¶…å¹³é¢ that divides the input space into two regions\n",
    "        For inputs on one side of the hyperplane, the output is 0\n",
    "        For inputs on the other side, the output is 1\n",
    "    Functions that can be computed in this way are called linearly separableçº¿æ€§å¯åˆ†. With this structure, a perceptron (artificial neuron) can learn any linear relationshipä»»ä½•çº¿æ€§å…³ç³»\n",
    "3.2.2.Application\n",
    "    Limitation: What happens if the data is not linearly separable\n",
    "    AND, OR, and NOT become linearly separable,but XOR are not\n",
    "\n",
    "3.3.Multi Layer Perceptronå¤šå±‚æ„ŸçŸ¥å™¨\n",
    "    compute XOR, one approach is to rewrite it in terms of linearly separable functions such as AND, OR, and NOR, and then arrange several perceptronå¤šä¸ªæ„ŸçŸ¥å™¨æ’åˆ— into a network that combines these functions appropriately\n",
    "    However, in practice, we usually deal with raw dataåŸå§‹æ•°æ® rather than explicit logical expressions\n",
    "    perceptron learning algorithmâ€”that can learn the weights of a neural networkäº†è§£ç¥ç»ç½‘ç»œçš„æƒé‡ from a set of training examples\n",
    "\n",
    "3.4.Learning with Gradient Descent and Backpropagationé€šè¿‡æ¢¯åº¦ä¸‹é™å’Œåå‘ä¼ æ’­è¿›è¡Œå­¦ä¹ \n",
    "    to optimize over a family of continuous and differentiable functions\n",
    "    define an error functionè¯¯å·®å‡½æ•° (also called a loss function or cost function) ğ¸as half the sum, over all input items, of the square of the difference between the actual output ğ‘§ğ‘–and the target output ğ‘¡ğ‘–\n",
    "    goal is to find the minimum of the error function ğ¸æ‰¾åˆ°è¯¯å·®å‡½æ•° E çš„æœ€å°å€¼, and minimum of a function can be calculated through its derivativeå¯¼æ•°\n",
    "    We can use multi-variable derivative to adjust the weights in such a way as to take us in the steepest downhill direction. w â† wâˆ’ Î· ğğ‘¬/ğğ’˜ , Î· is called the learning rateå­¦ä¹ ç‡\n",
    "    If we use the step function as the transfer function, the error landscape is not smooth; it consists almost entirely of flat regions and \"shoulders,\" with occasional discontinuous jumps.\n",
    "    For a single-layer perceptron, this was not a problem, but for networks with two or more layers, it becomes a major obstacle.\n",
    "    To apply gradient descent successfully, neural networks needed to be redesigned so that the function from input to output would be smooth and differentiableå¹³æ»‘ä¸”å¯å¾®\n",
    "3.4.1.Learning rate identify the step sizeå­¦ä¹ ç‡ç¡®å®šæ­¥é•¿\n",
    "    The key idea is to replace the (discontinuous) step function with a differentiable function, such as the sigmoid or hyperbolic tangent g(s)= ğŸ/ğŸ+ğ’†^(âˆ’ğ’”)\n",
    "    We now describe how to compute the partial derivatives of the loss function with respect to each weightæŸå¤±å‡½æ•°ç›¸å¯¹äºæ¯ä¸ªæƒé‡çš„åå¯¼æ•°\n",
    "    For illustration, we consider a two-layer neural network with sigmoid activationæ¿€æ´» sigmoid çš„ä¸¤å±‚ç¥ç»ç½‘ç»œ at the hidden layer, as shown in the diagram\n",
    "    ğ‘¥ğ‘– are the inputs, ğ‘¦ğ‘– are the hidden units, ğ‘¤ğ‘–ğ‘— and ğ‘£ğ‘– are the weights, and ğ‘ğ‘– and ğ‘ are the biases\n",
    "    Chain Rule(ä¼šè€ƒ)\n",
    "\n",
    "3.4.2.Backpropagationåå‘ä¼ æ’­\n",
    "    Forward passå‰å‘ä¼ é€’: apply inputs to the â€œlowest layerâ€ and feed activations forward to get output\n",
    "    Calculate errorè®¡ç®—è¯¯å·®: difference between desired output and actual output \n",
    "    Backward passå‘åä¼ é€’: Propagate errors back through the network to adjust weights\n",
    "    Since our prediction is greater than the target value, we need to decrease the weighté™ä½æƒé‡ in order to reduce the prediction in the next iterations\n",
    "    As we propagate back to the weights in the earlier layers, the amount of adjustment (decrement) becomes smallerå˜å°. For example, the change in ğ‘¤13 is more significant than the change in ğ‘¤11\n",
    "\n",
    "3.5.Neural Networks Designç¥ç»ç½‘ç»œè®¾è®¡\n",
    "\n",
    "3.5.1.Exhaustive Analysis of the Systemå¯¹ç³»ç»Ÿçš„è¯¦å°½åˆ†æ\n",
    "    Is a neural network really the best solution for this problem? Do I have the necessary requirements?ç¥ç»ç½‘ç»œçœŸçš„æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜çš„æœ€ä½³è§£å†³æ–¹æ¡ˆå—ï¼Ÿæˆ‘æœ‰å¿…è¦çš„è¦æ±‚å—ï¼Ÿ\n",
    "    Neural Networks: The second-best optionç¥ç»ç½‘ç»œï¼šç¬¬äºŒå¥½çš„é€‰æ‹©\n",
    "        Neural networks are highly data-sensitive and usually require large datasets, since they need to learn a large number of parameters (ğ‘¤ğ‘–)\n",
    "        Collecting and preparing such data can be costly and time-consuming\n",
    "\n",
    "3.5.2.Preprocessingé¢„å¤„ç†\n",
    "    What steps should I take before feeding data into the networkåœ¨å°†æ•°æ®è¾“å…¥ç½‘ç»œä¹‹å‰ï¼Œæˆ‘åº”è¯¥é‡‡å–å“ªäº›æ­¥éª¤ï¼Ÿ\n",
    "    Dataæ•°æ®:\n",
    "        A neural network is essentially a black-box model designed for interpolation (with no guarantee of good performance in extrapolation).\n",
    "        Therefore, its effectiveness strongly depends on the quality and quantity of the data available.\n",
    "    Qualityè´¨é‡:\n",
    "        This refers to how well the available data represents the underlying function being approximated.\n",
    "    Quantityæ•°é‡:\n",
    "        Only with a sufficiently large dataset can we expect to correctly identify the parameters (weights) of a neural model.\n",
    "        If the available data is insufficient, data augmentation techniques can be used to expand it\n",
    "3.5.2.1.Data cleaning:\n",
    "    Detect and, if possible, eliminate outliers, empty values, etc. It might also help to detect correlations between variables.\n",
    "    Normalisation of variables:\n",
    "        Xn = (X- Xmin)/ (Xmax-Xmin); Xn âˆˆ [0,1] or Xn = 2*(X-Xmin)/(Xmax-Xmin) â€“ 1; Xn âˆˆ [-1,1]\n",
    "    It is necessary to perform the corresponding denormalization at the output stageè¾“å‡ºé˜¶æ®µ\n",
    "3.5.2.2.why data normalizationä¸ºä»€ä¹ˆè¦è¿›è¡Œæ•°æ®å½’ä¸€åŒ–\n",
    "    1. To ensure features are comparable in scale ç¡®ä¿åŠŸèƒ½åœ¨è§„æ¨¡ä¸Šå…·æœ‰å¯æ¯”æ€§\n",
    "        Many datasets include features with very different ranges (e.g., age in years vs. income in dollars).\n",
    "        Without normalization, features with larger scales can dominate smaller ones in distance-based or gradient-based models.\n",
    "    2. To improve training stability and speed æé«˜è®­ç»ƒç¨³å®šæ€§å’Œé€Ÿåº¦\n",
    "        Gradient descent converges faster when features are on a similar scale.\n",
    "        If not normalized, the loss landscape can become very steep in some directions and flat in others.\n",
    "\n",
    "3.5.3.Design of the Neural Network ç¥ç»ç½‘ç»œçš„è®¾è®¡\n",
    "    What should the architecture of my network look like? (e.g., number of layers, number of neurons per layer, choice of activation functions, and other hyperparameters). æˆ‘çš„ç½‘ç»œæ¶æ„åº”è¯¥æ˜¯ä»€ä¹ˆæ ·å­ï¼Ÿï¼ˆä¾‹å¦‚ï¼Œå±‚æ•°ã€æ¯å±‚ç¥ç»å…ƒæ•°ã€æ¿€æ´»å‡½æ•°çš„é€‰æ‹©å’Œå…¶ä»–è¶…å‚æ•°ï¼‰\n",
    "    Rule of thumbç»éªŒæ³•åˆ™: Nh should lead to a number of parameters (weights) Nw that: Nw < (Number of samples) / 10\n",
    "        The number of weights Nw of a MLP, with Ni neurons in its input layer, a hidden layer with Nh neurons, and No neurons in the output layer is: Nw = (Ni+1)*Nh+(Nh+1)*No\n",
    "    Conclusion: more parameters and deeper networks do not lead to better a performance necessarily.\n",
    "    There should be a proportion between your dataset size, problem complexity, etc. and number of parameters æ•°æ®é›†å¤§å°ã€é—®é¢˜å¤æ‚æ€§ç­‰ä¸å‚æ•°æ•°é‡ä¹‹é—´åº”è¯¥æœ‰ä¸€å®šæ¯”ä¾‹\n",
    "    In MLPs is demonstrated that using one hidden layer with a proper number of neurons is sufficient to approximate any non-linear function with an arbitrary precision degree (Universal Approximation Theorem)åœ¨ MLP ä¸­ï¼Œè¯æ˜ä½¿ç”¨å…·æœ‰é€‚å½“æ•°é‡ç¥ç»å…ƒçš„éšè—å±‚å°±è¶³å¤Ÿä»¥ä»»æ„ç²¾åº¦åº¦è¿‘ä¼¼ä»»ä½•éçº¿æ€§å‡½æ•°ï¼ˆé€šç”¨é€¼è¿‘å®šç†ï¼‰ã€‚\n",
    "    Activation functionsæ¿€æ´»å‡½æ•°:\n",
    "        A usual criterion is to use sigmoid functions or ReLUs in the hidden layer and linear functions in the output. However, sigmoids or softmax can also be used in the output.\n",
    "\n",
    "3.5.4.Training\n",
    "    What happens during the training phase?\n",
    "    Training a neural network is a hard process due to the complexity of the error function solution space, which can have numerous local minima, minimax points, etc\n",
    "    There are three main problems that can arise during training:\n",
    "        Biasåå·®\n",
    "        Overparameterizationè¿‡åº¦å‚æ•°åŒ–\n",
    "        Overfittingè¿‡æ‹Ÿåˆ\n",
    "    The latter two might affect the network's ability to generalize (high variance)æ³›åŒ–èƒ½åŠ›ï¼ˆé«˜æ–¹å·®ï¼‰\n",
    "3.5.4.1.Bias\n",
    "    refers to the systematic error introduced by approximating a real-world problem (which may be very complex) with a simpler model.åå·®æ˜¯æŒ‡é€šè¿‡ä½¿ç”¨æ›´ç®€å•çš„æ¨¡å‹è¿‘ä¼¼ç°å®ä¸–ç•Œçš„é—®é¢˜ï¼ˆå¯èƒ½éå¸¸å¤æ‚ï¼‰è€Œå¼•å…¥çš„ç³»ç»Ÿè¯¯å·®ã€‚\n",
    "    A high bias model makes strong assumptions about the data, leading to underfitting.é«˜åå·®æ¨¡å‹å¯¹æ•°æ®åšå‡ºå¼ºçƒˆçš„å‡è®¾ï¼Œå¯¼è‡´æ‹Ÿåˆä¸è¶³ã€‚\n",
    "    It canâ€™t capture the true complexity of the underlying relationshipå®ƒæ— æ³•æ•æ‰æ½œåœ¨å…³ç³»çš„çœŸæ­£å¤æ‚æ€§ã€‚\n",
    "    To Decrease Bias:\n",
    "        One way to reduce bias is to run multiple training processes starting from different randomly chosen initial weights (e.g., 20 or more attempts). This increases the chance of reaching a better local minimum.\n",
    "        Another approach is to increase the number of neurons in the hidden layer, which allows the model to better capture the complexity of the problem.\n",
    "            However, there is a trade-off: adding too many neurons can lead to high variance and overparameterization, causing the model to overfitæ·»åŠ è¿‡å¤šçš„ç¥ç»å…ƒä¼šå¯¼è‡´é«˜æ–¹å·®å’Œè¿‡åº¦å‚æ•°åŒ–ï¼Œå¯¼è‡´æ¨¡å‹è¿‡åº¦æ‹Ÿåˆã€‚\n",
    "3.5.4.2.Overfittingè¿‡æ‹Ÿåˆ\n",
    "    A model is considered overparameterized when it has more trainable parameters than the available training data can uniquely determine.\n",
    "    In simpler terms, the model has too many parameters relative to the size or complexity of the dataset.\n",
    "    As a result, it becomes powerful enough to memorizeè®°ä½ the training data (including noise) rather than learning the underlying general patterns\n",
    "    The neural network is trained by presenting it with the input and target values for all items in the training set\n",
    "    After completing the learning procedure, it must then predict the outputs for items in the test set\n",
    "    The goal is to accurately predict the target values for the test set based on the input attributes.\n",
    "    A common mistake to avoid is building a model that fits the training data very well but performs poorly on unseen test dataâ€”this problem is known as overfitting.è¿‡åº¦æ‹Ÿåˆ\n",
    "    In contrast, a model that achieves high accuracy on both the training and test sets is said to have good generalizationæ¦‚æ‹¬æ€§\n",
    "    To determine the optimal model parameters, the dataset is often divided into Training, Validation, and Test (generalization) setsä¸ºäº†ç¡®å®šæœ€ä½³æ¨¡å‹å‚æ•°ï¼Œæ•°æ®é›†é€šå¸¸åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•ï¼ˆæ³›åŒ–ï¼‰é›†ã€‚\n",
    "    Typically, as the number of hidden nodes increases, both the training and test errors initially decrease.\n",
    "    However, beyond a certain point, the training error may continue to decrease while the test error plateaus or even slightly increases. The approximate number of hidden nodes at which the test error is minimal is likely to achieve the best generalization performanceæµ‹è¯•è¯¯å·®æœ€å°çš„éšè—èŠ‚ç‚¹çš„è¿‘ä¼¼æ•°é‡å¯èƒ½ä¼šå®ç°æœ€ä½³çš„æ³›åŒ–æ€§èƒ½\n",
    "3.5.4.3.Conclusion:\n",
    "    Increasing the number of neurons can help reduce bias (underfitting), while limiting the number of neurons helps prevent overfitting (high variance). This balance reflects the well-known biasâ€“variance trade-off.å¢åŠ ç¥ç»å…ƒæ•°é‡æœ‰åŠ©äºå‡å°‘åå·®ï¼ˆæ¬ æ‹Ÿåˆï¼‰ï¼Œè€Œé™åˆ¶ç¥ç»å…ƒæ•°é‡æœ‰åŠ©äºé˜²æ­¢è¿‡åº¦æ‹Ÿåˆï¼ˆé«˜æ–¹å·®ï¼‰ã€‚è¿™ç§å¹³è¡¡åæ˜ äº†ä¼—æ‰€å‘¨çŸ¥çš„åå·®-æ–¹å·®æƒè¡¡ã€‚\n",
    "    In addition to adjusting the network size, there are other techniques available to address\n",
    "underfitting and overfitting, such as regularization, early stopping, and data augmentation.\n",
    "\n",
    "3.5.5.Testing and Evaluationæµ‹è¯•å’Œè¯„ä¼°\n",
    "    How should I evaluate the performance of my network\n",
    "    To test the generalization capability of the network, performance is evaluated on the test setåœ¨æµ‹è¯•é›†\n",
    "    Some common loss functions:\n",
    "        Mean Squared Error (MSE):\n",
    "        Mean Absolute Error (MAE):\n",
    "        Cross-Entropy (Binary Cross-Entropy (for 2 classes))\n",
    "\n",
    "3.6.Deep Learning æ·±åº¦å­¦ä¹ \n",
    "    If we denote the first layer as ğ‘“ 1 , the second layer is ğ‘“ 2 , and so on. The total number of layers defines the depthæ·±åº¦ of the model, which is why this approach is known as deep learningæ·±åº¦å­¦ä¹ \n",
    "3.6.1.depth\n",
    "    The depth of a model is defined as the total number of layers with learnable parameters, excluding theinput layer.ä¸åŒ…æ‹¬è¾“å…¥å±‚\n",
    "    Deeper networks can typically approximate more complex functions, while shallower models have fewer layers and are limited to approximating simpler functions.\n",
    "\n",
    "Deep learning is based on the philosophy of connectionism:è¿æ¥ä¸»ä¹‰\n",
    "    while an individual biological neuron is not particularly intelligent, a large population of neurons or features acting together can exhibit intelligent behavior\n",
    "    It is important to emphasize that the number of neurons must be large.ç¥ç»å…ƒçš„æ•°é‡å¿…é¡»å¾ˆå¤§\n",
    "    One of the key factors behind the dramatic improvement in neural network accuracy and the complexity of tasks they can handleâ€”from the 1980s to todayâ€”is the significant increase in network size\n",
    "\n",
    "    Deep learning refers to artificial neural networks with multiple layers that automatically learn\n",
    "patterns and representations from data\n",
    "    What makes a network â€œdeepâ€ is the presence of many layers of neurons, not just one or two. A shallow networkæµ…å±‚ç½‘ç»œ might have only a single hidden layer, whereas a deep networkæ·±åº¦ç½‘ç»œ can have hundreds or even thousands of layers\n",
    "\n",
    "    Universal Approximation Theoremé€šç”¨é€¼è¿‘å®šç†\n",
    "        One layer with many neurons:\n",
    "            wide hidden layeréå¸¸å®½çš„éšè—å±‚,\n",
    "            but it is still shallowæ·±åº¦è¾ƒä½ \n",
    "            computationally inefficient and does not capture hierarchical representations effectively (low precision)\n",
    "        Many layers, each with one neuron:\n",
    "            This network is extremely deep but very narrow.éå¸¸æ·±ï¼Œä½†éå¸¸ç‹­çª„\n",
    "            It qualifies as deep learningæ·±åº¦å­¦ä¹  because the depth (number of layers) is enormous.\n",
    "            However, with only one neuron per layer, the networkâ€™s expressive power is limited"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c36d9",
   "metadata": {},
   "source": [
    "# Week 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efdedcd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b38c218e",
   "metadata": {},
   "source": [
    "# Week 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8feeb715",
   "metadata": {},
   "source": [
    "5.1.Optimisation method ä¼˜åŒ–æ–¹æ³•\n",
    "    dvantages of gradient descent:æ¢¯åº¦ä¸‹é™çš„ä¼˜ç‚¹\n",
    "        Easy implementation.\n",
    "        Standard method that works generally well.\n",
    "    Drawbacks of gradient descent:æ¢¯åº¦ä¸‹é™çš„ç¼ºç‚¹\n",
    "        Slow and inefficient.\n",
    "        It might get stuck on local minima leading to suboptimal results\n",
    "    Improvements to gradient descent:æ¢¯åº¦ä¸‹é™çš„æ”¹è¿›\n",
    "        Momentum åŠ¨é‡: Add percentage of last movement to the actual one.\n",
    "        Stochastic batch (SGD) éšæœºæ‰¹æ¬¡: Estimate gradient using subsample set.\n",
    "        Adaptable estimation (Adam) é€‚åº”ä¼°è®¡: Adapt the learning rate for each weight of the neural network\n",
    "    The option to elegantly and efficiently calculate the gradient allows us to handle the optimisation problem using the full range of optimisation methods provided by nonlinear optimisation systems\n",
    "\n",
    "5.2.Asymptotic complexity æ¸è¿‘å¤æ‚åº¦\n",
    "    Complexity å¤æ‚æ€§: The complexity of an algorithm is a measure of the amount of resources it consumes.\n",
    "    Resource èµ„æº:\n",
    "        Time\n",
    "        Space\n",
    "        Memory\n",
    "        Drive\n",
    "\n",
    "5.3.Classes of problems é—®é¢˜ç±»åˆ«\n",
    "5.3.1.Class P:\n",
    "        A P problem can be solved in polynomial time in a deterministic computer.\n",
    "        The class P comprises problems that can be solved quickly.\n",
    "        Examples: Quicksort, binary search, matrix multiplication.\n",
    "5.3.2.Class NP:\n",
    "        An NP problem cannot be solved in a polynomial time using a deterministic computer (intractable problem).\n",
    "        The class NP comprises problems whose solutions can be verified quickly (PâŠ†NP).\n",
    "        Examples: subsets addition, Sudoku, TSP.\n",
    "5.3.3.Class NP-complete:\n",
    "        A class of problems for which it is unknown if they are tractable.\n",
    "        No one has found polynomial algorithms for any of them.\n",
    "        Some problems closely related to tractable problems.\n",
    "        All known algorithms for NP-complete problems require exponential time in relation to the size of the input.\n",
    "5.3.4.algorithms to solve an NP-complete problem\n",
    "5.3.4.1.Approximation è¿‘ä¼¼:\n",
    "        An algorithm that quickly finds a solution that may not be optimal but falls within a certain range of error. In some cases, finding a good approximation is sufficient to solve the problem, but not all NP-complete problems have good approximation algorithms.\n",
    "5.3.4.2.Heuristics and Metaheuristics å¯å‘å¼å’Œå…ƒå¯å‘å¼:\n",
    "        An algorithm that performs reasonably well in many cases. They are generally fast, but there is no measure of the quality of the answer.\n",
    "5.3.4.3.Genetic Algorithms é—ä¼ ç®—æ³•:\n",
    "        Algorithms that improve possible solutions until finding one that is possibly close to the optimum. There is also no guarantee of the quality of the answer.\n",
    "\n",
    "5.4.Search spaceæœç´¢ç©ºé—´\n",
    "    Feasible solution: is in the feasible region of the problem.\n",
    "    Solution space S and objective function f.\n",
    "    The optimisation problem O(S, f) is solved by determining an optimal solution, i.e., a feasible solution x0 âˆˆ S / f(x) â‰¤ f(x0 ) â±¯ x âˆˆ S.\n",
    "    Constraints of the problem reduce the universe of solutions U, then X âŠ† U, also called feasible region.\n",
    "\n",
    "5.4.1.Neighbourhood search procedures é‚»é‡ŒæœæŸ¥ç¨‹åº:\n",
    "    Transformations or movements from the current solution.\n",
    "        Generate an initial solution.\n",
    "        Iteratively modify it until a stopping criterion.\n",
    "        Solutions are evaluated while traversing.\n",
    "    Possible movements create a neighbourhood.\n",
    "    Feasible movements are those that provide a feasible solution.\n",
    "\n",
    "5.4.2.Constraints çº¦æŸ:\n",
    "    Can be strong (must be satisfied) or weak (recommended to be satisfied).\n",
    "        Example: In course scheduling, a strong constraint is that classes should not overlap, while a weak constraint is that there should be no classes after 4pm.\n",
    "\n",
    "5.4.3.Restricted exploration of the feasible region within the search space æœç´¢ç©ºé—´å†…å¯è¡ŒåŒºåŸŸçš„æœ‰é™æ¢ç´¢:\n",
    "    Advantages: Infeasible solutions are not evaluated. The algorithms ensure obtaining a feasible solution.\n",
    "    Disadvantages: The search can be inefficient if restricted only to the feasible region. Optimal solutions may be located near the boundary and difficult to reach.\n",
    "\n",
    "5.4.4.Complete exploration of the solution space å®Œæ•´æ¢ç´¢è§£å†³æ–¹æ¡ˆç©ºé—´:\n",
    "    Advantages: The exploration of the search space is more effective.\n",
    "    Disadvantages: Time is spent evaluating infeasible solutions. There is a possibility of returning an infeasible solution as the final output of the algorithm.\n",
    "\n",
    "5.4.5.Three strategies for restricted exploration of the feasible region within the search space:\n",
    "    Rejection strategies æ‹’ç»ç­–ç•¥: Any infeasible solution generated during the search is directly ignored.\n",
    "    Repair strategies ä¿®å¤ç­–ç•¥: A repair operator is applied to each infeasible solution generated to transform it into a feasible solution. This strategy is often based on heuristics.\n",
    "    Preservation strategies ä¿å­˜ç­–ç•¥: Both the representation scheme and the operators are specifically designed for the problem in a way that ensures the feasibility of generated solutions. It requires more design effort and are problem-specific.\n",
    "\n",
    "5.4.6.Complete exploration of the solution space å®Œæ•´æ¢ç´¢è§£å†³æ–¹æ¡ˆç©ºé—´:\n",
    "    The most common scheme for complete exploration of the solution space is penalty-based strategies:\n",
    "        A penalty function is added to the original unconstrained objective function: Min f'(x) = f(x) + wÂ·P(x)\n",
    "        where P(x) is a penalty function and w is a weighting coefficient (intensify/diversify).\n",
    "        P(x) takes a value of 0 when the solution x is feasible. Otherwise, the greater the degree of constraint violation, the larger the value of P\n",
    "\n",
    "5.5.Memoryless and memory-based metaheuristics æ— è®°å¿†å’ŒåŸºäºè®°å¿†çš„å…ƒå¯å‘å¼\n",
    "5.5.1.Metaheuristics å…ƒå¯å‘å¼\n",
    "    Metaheuristics provide strategies for solving a problem by conducting a search over the space of possible solutions.\n",
    "    The solution representation must include all the necessary information for their identification and evaluation.\n",
    "    A search over a space involves generating a sequence of points in the space, where each point is obtained from the previous one through a series of transformations or movements.\n",
    "    The goal of search-based metaheuristics is to provide guidelines for obtaining paths that yield high-quality solutions while also ensuring adequate effciency\n",
    "5.5.1.1.Memoryless metaheuristics æ— è®°å¿†å…ƒå¯å‘å¼: \n",
    "    do not use or maintain any explicit memory of past search information. They rely solely on the current solution and its neighborhood to make decisions about the next search move. These metaheuristics typically focus on exploration by using randomized or stochastic search techniques.\n",
    "5.5.1.2.Memory-based metaheuristics åŸºäºè®°å¿†çš„å…ƒå¯å‘å¼: \n",
    "    are algorithms that use past information or historical data to guide the search process. They remember and store certain aspects of the search, such as the best solutions found so far or promising regions in the solution space. This memory allows them to make informed decisions and adapt their search strategy based on past experience\n",
    "5.5.1.3.Simulated annealing æ¨¡æ‹Ÿé€€ç« è¦è€ƒï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼ï¼\n",
    "    is a probabilistic optimisation algorithm inspired by the annealing process in metallurgy. It is used to find near-optimal solutions for combinatorial optimisation problems.\n",
    "5.5.1.4.Tabu search Tabu æœç´¢\n",
    "is an algorithm used for solving optimisation problems. It is based on the concept of maintaining a tabu list, which keeps track of recently visited solutions to prevent cycling and encourage exploration.\n",
    "\n",
    "5.6.Population-based method åŸºäºäººå£çš„æ–¹æ³•\n",
    "    Operate on a population of candidate solutions rather than a single solution. The population is typically initialized randomly or using heuristic techniques.\n",
    "    Multiple solutions are evaluated simultaneously, allowing for the exploration of the search space more efficiently.\n",
    "        Advantages ä¼˜ç‚¹: ability to simultaneously explore multiple regions of the search space, promoting diversity and preventing premature convergence to suboptimal solutions.\n",
    "        Disadvantages ç¼ºç‚¹: it may require careful parameter tuning and can be computationally demanding due to the population size and iterative nature of the algorithms.\n",
    "    Examples of bio-inspired population-based methods include ant colony optimisation, black hole algorithm, particle swarm optimisation, and genetic algorithms.\n",
    "\n",
    "5.6.1.Swarm optimisation ç¾¤ä½“ä¼˜åŒ–\n",
    "    refers to a family of nature-inspired optimisation algorithms that mimic the collective behaviour of decentralised, self-organised systems found in nature (e.g., bird flocks, fish schools, or ant colonies) to find optimal or near-optimal solutions to complex problems.\n",
    "    The main idea is that a population (swarm) of simple agents (particles, ants, bees, etc.) explores the search space collaboratively. Each agent follows simple rules based on its own experience and that of its neighbours, and through many iterations, the swarm converges toward good/reasonable solutions.\n",
    "    The main concepts of swarm optimisation are:\n",
    "        Population-based åŸºäºäººå£: Many candidate solutions evolve simultaneously.\n",
    "        Decentralised å»ä¸­å¿ƒåŒ–: No single agent controls the process, so intelligence emerges from interaction.\n",
    "        Stochastic éšæœºæŒ‡æ ‡: Uses randomness to explore the search space and avoid local minima.\n",
    "        Adaptive è‡ªé€‚åº”: Agents adjust their behaviour based on feedback.\n",
    "    Some warm optimisation algorithms:\n",
    "        Particle Swarm Optimisation (PSO) ç²’å­ç¾¤ä¼˜åŒ–: Inspired by bird flocking. Each particle adjusts its position based on its own best position and the swarmâ€™s best-known position.\n",
    "        Ant Colony Optimisation (ACO) èšç¾¤ä¼˜åŒ–: Inspired by how ants find shortest paths. Ants deposit pheromones that guide others toward better solutions.\n",
    "        Artificial Bee Colony (ABC) äººå·¥èœ‚ç¾¤: Based on how bees search for food sources and share information.\n",
    "    Applications: function optimisation, robotics path planning, scheduling and resource allocation, neural network training, feature selection in machine learning.\n",
    "\n",
    "5.6.2.Genetic algorithms é—ä¼ ç®—æ³•\n",
    "    Based on Darwinâ€™s evolution theory.\n",
    "    â€œOne general law, leading to the advancement of all organic beings, namely, multiply, vary, let the strongest live and the weakest die.â€ Charles Darwin.\n",
    "    Stochastic search éšæœºæœç´¢ technique based on the mechanisms of natural selection and natural genetics.\n",
    "    Use analogies ç±»æ¯” of natural selection to develop better solutions.\n",
    "    Widely used in problems of nonlinear and high-dimensional optimis\n",
    "    GA model the process of evolution as a sequence of changes in genes, with solutions analogous to chromosomes.\n",
    "    The search space is explored by applying transformations to candidate solutions, just as observed in living organisms: crossover, mutation, and selection\n",
    "    Terminology used in genetic algorithms é—ä¼ ç®—æ³•ä¸­ä½¿ç”¨çš„æœ¯è¯­:\n",
    "\n",
    "5.6.2.1.Three main operators: crossover, mutation, and selection ä¸‰ä¸ªä¸»è¦ç®—å­ï¼šäº¤å‰ã€çªå˜å’Œé€‰æ‹©\n",
    "        Genetic: crossover and mutation. They emulate the process of gene inheritance to create new solutions. Evolution: selection. It emulates Darwinian evolution to create a population from one generation to another.\n",
    "        Crossover: operates on 2 chromosomes, generating two offspring by combining characteristics. The performance of the algorithm highly depends on this operation.\n",
    "            Crossover rate (p c ): the number of offspring produced each generation divided by the population size.\n",
    "        Mutation: operates on 1 chromosome, producing random spontaneous changes in a gene, contributing to exploration of the search space.\n",
    "            Mutation rate (pm ): percentage of the total number of genes in the population to mutate. It controls the rate at which new genes are introduced into the population.\n",
    "        Selection: the selective pressure is critical for the algorithm.\n",
    "            High pressure: the search may end prematurely (intensification).\n",
    "            Low pressure: progress is slower than necessary (diversification).\n",
    "        The ideal approach is to maintain low pressure at the beginning for broad exploration, and high pressure towards the end to exploit more promising areas\n",
    "5.6.2.2.General structure:\n",
    "    Chromosome commonly represented as strings of bits or binary representation.\n",
    "    Parameters include population size and probability of applying the genetic operators\n",
    "5.6.2.3.New generation size: Uniform\n",
    "    New generation size = Same as previous generation\n",
    "    All offspring and some parents. Originally, all offspring replaced all parents\n",
    "5.6.2.4.New generation size: Expanded\n",
    "    New generation size = Previous generation size + number of offspring\n",
    "    All offspring and parents\n",
    "5.6.2.5.\n",
    "    Stochastic sampling: prevent super chromosomes. For instance, roulette wheel.\n",
    "    Deterministic sampling: sort chromosomes according to their fitness and choose the best ones. Elitist selection."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
