{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e293d82f-6930-4e1c-9db3-a0871abc11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e67c24-409d-4e86-9a7b-a199e24efc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### 3.1 Exercise #####################################\n",
    "\n",
    "############################ 3.1.1 and 3.1.2 ####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3be5b-71b0-4c05-9669-aefd32bd6e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading RGB image\n",
    "img1 = cv2.imread('parrots.jpg')\n",
    "\n",
    "cv2.imshow('Original image',img1)\n",
    "print(img1)\n",
    "print(img1.shape)\n",
    "\n",
    "img1_red=img1.copy()\n",
    "img1_red[:,:,2]=255\n",
    "cv2.imshow('Original image in red',img1_red)\n",
    "\n",
    "\n",
    "#Reading grey-scale image\n",
    "img2 = cv2.imread('parrots.jpg',0)\n",
    "cv2.imshow('Gray-scale image',img2)\n",
    "print(img2)\n",
    "print(img2.shape)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04874c12-641c-4221-9f99-df0675977e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 3.1.3 ####################################\n",
    "\n",
    "cv2.imwrite('parrots_gray_test.jpg',img2)\n",
    "\n",
    "\n",
    "############################ 3.1.4 ####################################\n",
    "\n",
    "#img1 = cv2.imread('parrots.jpg')\n",
    "\n",
    "height=img1.shape[0]\n",
    "width=img1.shape[1]\n",
    "print(height,width)\n",
    "\n",
    "test=img1.copy()\n",
    "\n",
    "#Making frame\n",
    "##### TO DO PART ####\n",
    "# Change test in order to create a frame. \n",
    "\n",
    "cv2.imshow('Frame test',test)\n",
    "cv2.imwrite('parrots_frame_test.jpg',test)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a6d99e-ad77-41b8-a03e-bce2acfa8805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a166e-df9b-44bb-87eb-0f9df902319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 3.1.5 ####################################\n",
    "#######TO DO PART ####\n",
    "# creat a random noise matrix with the same shape of the image with values between 0 - 50.\n",
    "noise=...\n",
    "print(noise)\n",
    "\n",
    "cv2.imwrite('noise.jpg',noise)\n",
    "noise=cv2.imread('noise.jpg',0)\n",
    "cv2.imshow('Noise',noise)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "############################ 3.1.6 ####################################\n",
    "## To Do Part##\n",
    "# add the noise to your picture and display it\n",
    "noiseimg = cv2.add(img2, noise)\n",
    "\n",
    "result=cv2.imshow('Image noisy',noiseimg)\n",
    "cv2.imwrite('parrots_noisy_test.jpg', noiseimg)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9725a680-0618-46fe-961f-f9e67f9c3573",
   "metadata": {},
   "source": [
    "In the following section we will use matplotlip to display our images rather than OpenCV. You can choose your own preference; however, sometimes OpenCV imshow function is not compatible with Jupyter notebook. That happens because cv2.imshow() function is designed to work with desktop windows, which Jupyter doesn't handle well. Jupyter is typically web-based."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8205f095-c167-4dde-b5bd-57f4185ec1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_image(image, title='Image'):\n",
    "    # Display image using matplotlib\n",
    "    plt.figure()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "############################ 3.2.1 ####################################\n",
    "#### To do part ###\n",
    "def mean_filter(image):\n",
    "    img = image.copy()\n",
    "    output = np.zeros_like(img)\n",
    "    for i in range(1, h - 1):\n",
    "        for j in range(1, w - 1):\n",
    "            window = img[i - 1:i + 2, j - 1:j + 2]\n",
    "            output[i, j] = np.mean(window)\n",
    "    return output\n",
    "\n",
    "############################ 3.2.2 ####################################\n",
    "def median_filter(image):\n",
    "    img_prime = image.copy()\n",
    "    h, w = img_prime.shape\n",
    "    img_prime = np.zeros_like(img_prime)\n",
    "    for i in range(1, h - 1):\n",
    "        for j in range(1, w - 1):\n",
    "            window = img_prime[i - 1:i + 2, j - 1:j + 2]\n",
    "            img_prime[i, j] = np.median(window)\n",
    "    return img_prime\n",
    "\n",
    "# Load images\n",
    "img1 = cv2.imread('parrots.jpg', 0)\n",
    "img2 = cv2.imread('parrots_noisy_test.jpg', 0)\n",
    "\n",
    "# Show the original noisy image\n",
    "show_image(img1, 'Gray-scale Image')\n",
    "show_image(img2, 'Noisy Image')\n",
    "\n",
    "# Apply filters and show results\n",
    "mean_filtered = mean_filter(img2)\n",
    "show_image(mean_filtered, 'Mean Filtered Image')\n",
    "\n",
    "median_filtered = median_filter(img2)\n",
    "show_image(median_filtered, 'Median Filtered Image')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35730752-8119-4b1e-9fb4-1e02e433685d",
   "metadata": {},
   "source": [
    "In the mean filter, could we use n = (image[i-1,j-1] + image[i,j-1] + image[i-1,j] + ... + image[i,j]) / 9 instead of a=image[i-1,j-1]/9, b=image[i,j-1]/9, c=image[i-1,j]/9, ..., k=image[i,j]/9, n=a+b+c+d+e+f+g+h+k? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17188e-56e3-440a-911c-289b7f2611a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 3.2.3 ####################################\n",
    "window=3\n",
    "\n",
    "# Apply the mean filter\n",
    "ksize = (window, window)  # Size of the filter kernel\n",
    "opencv_mean_image = cv2.blur(img2, ksize)\n",
    "\n",
    "\n",
    "# Apply the median filter\n",
    "ksize = window  # Size of the filter kernel (window size)\n",
    "opencv_median_image = cv2.medianBlur(img2, ksize)\n",
    "\n",
    "cv2.imshow('OpenCV filtered image (mean)',opencv_mean_image)\n",
    "cv2.imshow('OpenCV filtered image (median)',opencv_median_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cae873-a90a-4766-b557-8f1ca7728dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#captures all the frames\n",
    "video = cv2.VideoCapture('tom_and_jerry.mp4')\n",
    "\n",
    "#Check if video opened successfully\n",
    "if (video.isOpened()== False): \n",
    "    print(\"Error opening video stream or file\")\n",
    "\n",
    "#fram/sec in video and duration of it\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "print('frames per second =',fps)\n",
    "\n",
    "#total number of frames\n",
    "length = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('total number of frames =',length)\n",
    "print('duration of the video (in sec) =',length/fps)\n",
    "\n",
    "video.set(cv2.CAP_PROP_POS_FRAMES, 1002)\n",
    "ret, frame = video.read()\n",
    "cv2.imshow('Frame 1002', frame)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3243161f-d741-4c8f-96e1-f5275130f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 4.1.2 ####################################\n",
    " \n",
    "# Read until video is completed\n",
    "while(video.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = video.read()\n",
    "  if ret == True:\n",
    "  #### To Do ######\n",
    "  #define the canny filter and apply it on the image.    \n",
    "    edges = cv2.Canny(frame, 100, 200)\n",
    "    cv2.imshow('Canny Filter', edges)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:         # wait for ESC key to exit, 27 is the escape key number\n",
    "      break\n",
    " \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    "# When everything done, release the video capture object\n",
    "video.release()\n",
    "# Closes all the frames\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08a9a2a-ed6a-4454-80fd-200a9085ecc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aad6a4-a293-448f-a225-baf26a71e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### 5.1 Exercise #####################################\n",
    "\n",
    "############################ 5.1.2 and 5.1.3 ####################################\n",
    "\n",
    "\n",
    "# import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "# import cv2\n",
    "\n",
    "\n",
    "\n",
    "## Loading MNIST dataset\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "\n",
    "## MNIST dataset images are 28*28, and they are between 0-255. \n",
    "#Preprocessing part 1 \n",
    "\n",
    "\n",
    "## Transforming labels\n",
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)\n",
    "\n",
    "\n",
    "## Preprocessing part 2\n",
    "\n",
    "\n",
    "\n",
    "## Loading VGG16 model\n",
    "base_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "base_model.trainable = False ## Not trainable weights\n",
    "\n",
    "\n",
    "############################ 5.1.4 ####################################\n",
    "\n",
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eeb3c0-b62c-4382-920b-87eb1e892ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 5.1.5 ####################################\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "#### TO DO PART ####\n",
    "# add the requested layers\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "es = EarlyStopping(monitor='val_accuracy', mode='max', patience=5, restore_best_weights=True)\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "history = model.fit(train_ds, train_labels, epochs=5, validation_split=0.2, batch_size=32, callbacks=[es])\n",
    "\n",
    "score = model.evaluate(test_ds, test_labels, batch_size=32)\n",
    "x_valid_output_images = model.predict(test_ds)\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "\n",
    "############################ 5.1.6 ####################################\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, history.history['loss'], 'r--')\n",
    "plt.plot(epoch_count, history.history['val_loss'], 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Training time:', str(elapsed))\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242b809f-638a-4a1e-bb6e-e1df2ebe2e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ 5.1.7 ####################################\n",
    "\n",
    "\n",
    "## Loading MNIST dataset\n",
    "(train_ds, train_labels), (test_ds, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "## Displaying an image\n",
    "image_index = 10\n",
    "plt.imshow(train_ds[image_index], cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "## TO DO PART ###\n",
    "# Preprocessing  images\n",
    "input_image = train_ds[image_index]\n",
    "input_image = np.stack((input_image,)*3, axis=-1)\n",
    "input_image = cv2.resize(input_image, (32, 32))\n",
    "input_image = preprocess_input(np.expand_dims(input_image, axis=0))\n",
    "\n",
    "predicted_label = model.predict(input_image)\n",
    "predicted_class = np.argmax(predicted_label)\n",
    "\n",
    "actual_class = np.argmax(to_categorical(train_labels[image_index], 10))\n",
    "\n",
    "print(\"Actual class:\", actual_class)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc96f91a-ee1f-4502-85ef-e23c1fba6715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp_9814",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
